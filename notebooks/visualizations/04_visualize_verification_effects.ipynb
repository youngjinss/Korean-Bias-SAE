{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification Effects Visualization\n",
    "\n",
    "This notebook visualizes the effects of suppressing or amplifying bias features.\n",
    "\n",
    "**Purpose:**\n",
    "- Verify that identified bias features actually cause bias predictions\n",
    "- Compare suppression vs. amplification vs. random control\n",
    "- Quantify effect sizes across demographics\n",
    "\n",
    "**Input Data:**\n",
    "- Verification results (baseline, suppress, amplify, random)\n",
    "- Logit gaps before and after manipulation\n",
    "\n",
    "**Output:**\n",
    "- 3×3 grid of bar charts showing effects per demographic\n",
    "- Effect size summary statistics\n",
    "- Statistical significance tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent.parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from src.visualization import (\n",
    "    setup_korean_font,\n",
    "    load_demographics,\n",
    "    load_verification_results,\n",
    "    plot_verification_effects,\n",
    "    get_demographic_labels\n",
    ")\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "setup_korean_font()\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "ASSETS_DIR = PROJECT_ROOT / \"notebooks\" / \"visualizations\" / \"assets\"\n",
    "ASSETS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "STAGE = \"mock\"\n",
    "\n",
    "print(f\"Stage: {STAGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demographics\n",
    "demographics_dict = load_demographics(DATA_DIR)\n",
    "demographic_labels_ko, demographic_labels_en = get_demographic_labels(demographics_dict)\n",
    "\n",
    "# Load verification results\n",
    "verification_results = load_verification_results(RESULTS_DIR, stage=STAGE)\n",
    "\n",
    "print(f\"Loaded verification results for {len(verification_results)} demographics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Verification Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_verification_effects(\n",
    "    verification_results=verification_results,\n",
    "    demographic_labels_ko=demographic_labels_ko,\n",
    "    demographic_labels_en=demographic_labels_en,\n",
    "    save_path=ASSETS_DIR / f\"verification_effects_{STAGE}.png\",\n",
    "    figsize=(18, 15)\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect Size Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute effect sizes\n",
    "effect_sizes = []\n",
    "\n",
    "for demo_ko in demographic_labels_ko:\n",
    "    if demo_ko not in verification_results:\n",
    "        continue\n",
    "    \n",
    "    results = verification_results[demo_ko]\n",
    "    baseline = results.get('baseline_gap_mean', 0)\n",
    "    \n",
    "    if baseline > 0:\n",
    "        suppress_effect = (results.get('suppress_gap_mean', 0) - baseline) / baseline\n",
    "        amplify_effect = (results.get('amplify_gap_mean', 0) - baseline) / baseline\n",
    "        random_effect = (results.get('random_gap_mean', 0) - baseline) / baseline\n",
    "    else:\n",
    "        suppress_effect = 0\n",
    "        amplify_effect = 0\n",
    "        random_effect = 0\n",
    "    \n",
    "    effect_sizes.append({\n",
    "        'Demographic': demo_ko,\n",
    "        'Baseline Gap': baseline,\n",
    "        'Suppress Effect (%)': suppress_effect * 100,\n",
    "        'Amplify Effect (%)': amplify_effect * 100,\n",
    "        'Random Effect (%)': random_effect * 100,\n",
    "        'Suppress Std': results.get('suppress_gap_std', 0),\n",
    "        'Amplify Std': results.get('amplify_gap_std', 0),\n",
    "    })\n",
    "\n",
    "df_effects = pd.DataFrame(effect_sizes)\n",
    "\n",
    "print(\"\\nVerification Effect Sizes:\")\n",
    "print(\"=\" * 100)\n",
    "print(df_effects.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "df_effects.to_csv(ASSETS_DIR / f\"verification_effect_sizes_{STAGE}.csv\", index=False)\n",
    "print(f\"\\nSaved to {ASSETS_DIR / f'verification_effect_sizes_{STAGE}.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare effect sizes across demographics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Suppress effects\n",
    "ax = axes[0]\n",
    "x = np.arange(len(df_effects))\n",
    "ax.barh(x, df_effects['Suppress Effect (%)'], color='blue', alpha=0.7)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(df_effects['Demographic'])\n",
    "ax.set_xlabel('Effect (%)', fontsize=12)\n",
    "ax.set_title('억제 효과\\nSuppression Effects', fontsize=14, pad=10)\n",
    "ax.axvline(0, color='black', linewidth=0.8)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Amplify effects\n",
    "ax = axes[1]\n",
    "ax.barh(x, df_effects['Amplify Effect (%)'], color='red', alpha=0.7)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(df_effects['Demographic'])\n",
    "ax.set_xlabel('Effect (%)', fontsize=12)\n",
    "ax.set_title('증폭 효과\\nAmplification Effects', fontsize=14, pad=10)\n",
    "ax.axvline(0, color='black', linewidth=0.8)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Random effects (should be near zero)\n",
    "ax = axes[2]\n",
    "ax.barh(x, df_effects['Random Effect (%)'], color='orange', alpha=0.7)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(df_effects['Demographic'])\n",
    "ax.set_xlabel('Effect (%)', fontsize=12)\n",
    "ax.set_title('무작위 대조군\\nRandom Control', fontsize=14, pad=10)\n",
    "ax.axvline(0, color='black', linewidth=0.8)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ASSETS_DIR / f\"effect_sizes_comparison_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Criteria Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation criteria:\n",
    "# - Suppress should reduce gap by >5%\n",
    "# - Amplify should increase gap by >5%\n",
    "# - Random should have <5% effect\n",
    "\n",
    "THRESHOLD = 5.0  # percent\n",
    "\n",
    "success_counts = {\n",
    "    'suppress_success': 0,\n",
    "    'amplify_success': 0,\n",
    "    'random_minimal': 0,\n",
    "    'total': len(df_effects)\n",
    "}\n",
    "\n",
    "print(\"\\nSuccess Criteria Evaluation:\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"Threshold: ±{THRESHOLD}%\\n\")\n",
    "\n",
    "for _, row in df_effects.iterrows():\n",
    "    demo = row['Demographic']\n",
    "    suppress = row['Suppress Effect (%)']\n",
    "    amplify = row['Amplify Effect (%)']\n",
    "    random = row['Random Effect (%)']\n",
    "    \n",
    "    suppress_ok = suppress < -THRESHOLD\n",
    "    amplify_ok = amplify > THRESHOLD\n",
    "    random_ok = abs(random) < THRESHOLD\n",
    "    \n",
    "    if suppress_ok:\n",
    "        success_counts['suppress_success'] += 1\n",
    "    if amplify_ok:\n",
    "        success_counts['amplify_success'] += 1\n",
    "    if random_ok:\n",
    "        success_counts['random_minimal'] += 1\n",
    "    \n",
    "    status = '✓' if (suppress_ok and amplify_ok and random_ok) else '✗'\n",
    "    print(f\"{status} {demo:15s} | Suppress: {suppress:+6.1f}% {'✓' if suppress_ok else '✗'} | \"\n",
    "          f\"Amplify: {amplify:+6.1f}% {'✓' if amplify_ok else '✗'} | \"\n",
    "          f\"Random: {random:+6.1f}% {'✓' if random_ok else '✗'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(f\"\\nOverall Success Rates:\")\n",
    "print(f\"  Suppress success: {success_counts['suppress_success']}/{success_counts['total']} \"\n",
    "      f\"({success_counts['suppress_success']/success_counts['total']*100:.1f}%)\")\n",
    "print(f\"  Amplify success:  {success_counts['amplify_success']}/{success_counts['total']} \"\n",
    "      f\"({success_counts['amplify_success']/success_counts['total']*100:.1f}%)\")\n",
    "print(f\"  Random minimal:   {success_counts['random_minimal']}/{success_counts['total']} \"\n",
    "      f\"({success_counts['random_minimal']/success_counts['total']*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\nEffect Size Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for effect_type in ['Suppress Effect (%)', 'Amplify Effect (%)', 'Random Effect (%)']:\n",
    "    values = df_effects[effect_type]\n",
    "    print(f\"\\n{effect_type}:\")\n",
    "    print(f\"  Mean:   {values.mean():+7.2f}%\")\n",
    "    print(f\"  Median: {values.median():+7.2f}%\")\n",
    "    print(f\"  Std:    {values.std():7.2f}%\")\n",
    "    print(f\"  Min:    {values.min():+7.2f}%\")\n",
    "    print(f\"  Max:    {values.max():+7.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "### Expected Results:\n",
    "\n",
    "1. **Suppression (Blue bars):**\n",
    "   - Should show negative effect (decrease in logit gap)\n",
    "   - Target: >5% reduction\n",
    "   - Indicates features contribute to bias\n",
    "\n",
    "2. **Amplification (Red bars):**\n",
    "   - Should show positive effect (increase in logit gap)\n",
    "   - Target: >5% increase\n",
    "   - Confirms features are causal for bias\n",
    "\n",
    "3. **Random Control (Orange bars):**\n",
    "   - Should be near zero (<5% change)\n",
    "   - Validates specificity of identified features\n",
    "   - Rules out non-specific effects\n",
    "\n",
    "### What to Look For:\n",
    "\n",
    "- **Strong Effects:** Which demographics show largest suppression/amplification?\n",
    "- **Asymmetry:** Are suppress/amplify effects symmetric?\n",
    "- **Controls:** Are random effects truly minimal?\n",
    "- **Consistency:** Do effects align with IG² scores?\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Investigate demographics with weak effects\n",
    "2. Test different feature thresholds\n",
    "3. Examine individual feature contributions\n",
    "4. Correlate with real-world bias metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
