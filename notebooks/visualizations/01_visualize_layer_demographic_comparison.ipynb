{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Layer & Demographic Comparison Analysis\n",
    "\n",
    "This notebook provides comprehensive visualizations comparing results across:\n",
    "- **3 EXAONE layers**: Q1 (25%), Q2 (50%), Q3 (75%)\n",
    "- **9 demographic dimensions**: 성별, 인종, 종교, 나이, 직업, 학력, 지역, 정치성향, 성적지향\n",
    "\n",
    "## Visualizations:\n",
    "\n",
    "1. **Probe Accuracy Comparison**: Linear probe accuracy by layer and demographic\n",
    "2. **IG² Score Comparison**: Top IG² scores by layer and demographic\n",
    "3. **Training Loss Comparison**: SAE and probe training curves\n",
    "\n",
    "## Prerequisites:\n",
    "- Run pipeline for all 9 demographics and all 3 layers\n",
    "- Results stored in `results/{stage}/{demographic}/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.visualization import ensure_korean_font\n",
    "from src.utils import load_json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Korean font\n",
    "font_name = ensure_korean_font()\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "ASSETS_DIR = PROJECT_ROOT / \"notebooks\" / \"visualizations\" / \"assets\"\n",
    "ASSETS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Stage\n",
    "STAGE = \"full\"\n",
    "\n",
    "# SAE type\n",
    "SAE_TYPE = \"gated\"\n",
    "\n",
    "# Layer quantiles to compare\n",
    "LAYER_QUANTILES = [\"q1\", \"q2\", \"q3\"]\n",
    "LAYER_LABELS = {\n",
    "    \"q1\": \"Layer Q1 (25%)\",\n",
    "    \"q2\": \"Layer Q2 (50%)\",\n",
    "    \"q3\": \"Layer Q3 (75%)\"\n",
    "}\n",
    "\n",
    "# Load demographics\n",
    "demo_dict = load_json(DATA_DIR / \"demographic_dict_ko.json\")\n",
    "DEMOGRAPHICS = list(demo_dict.keys())\n",
    "DEMOGRAPHIC_EN = {d: demo_dict[d]['dimension_en'] for d in DEMOGRAPHICS}\n",
    "\n",
    "print(f\"Stage: {STAGE}\")\n",
    "print(f\"SAE Type: {SAE_TYPE}\")\n",
    "print(f\"Layer Quantiles: {LAYER_QUANTILES}\")\n",
    "print(f\"\\nDemographics ({len(DEMOGRAPHICS)}):\")\n",
    "for d in DEMOGRAPHICS:\n",
    "    print(f\"  - {d} ({DEMOGRAPHIC_EN[d]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_probe_results(results_dir, stage, demographic, layer_quantile):\n",
    "    \"\"\"\n",
    "    Load linear probe training results.\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'accuracy', 'best_accuracy', 'losses', etc.\n",
    "        or None if not found\n",
    "    \"\"\"\n",
    "    # Use layer-specific filename (new format)\n",
    "    probe_path = results_dir / stage / demographic / 'probe' / f'{layer_quantile}_linear_probe.pt'\n",
    "    metrics_path = results_dir / stage / demographic / 'probe' / f'{layer_quantile}_training_metrics.pkl'\n",
    "    \n",
    "    # Fallback to legacy non-layer-specific path\n",
    "    if not probe_path.exists():\n",
    "        probe_path = results_dir / stage / demographic / 'probe' / 'linear_probe.pt'\n",
    "        metrics_path = results_dir / stage / demographic / 'probe' / 'training_metrics.pkl'\n",
    "    \n",
    "    if not probe_path.exists():\n",
    "        return None\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    # Load probe checkpoint\n",
    "    checkpoint = torch.load(probe_path, map_location='cpu')\n",
    "    result['final_accuracy'] = checkpoint.get('final_accuracy', 0)\n",
    "    result['best_accuracy'] = checkpoint.get('best_accuracy', 0)\n",
    "    result['layer_quantile'] = checkpoint.get('layer_quantile', layer_quantile)\n",
    "    \n",
    "    # Load training metrics if available\n",
    "    if metrics_path.exists():\n",
    "        with open(metrics_path, 'rb') as f:\n",
    "            metrics = pickle.load(f)\n",
    "        result['losses'] = metrics.get('losses', [])\n",
    "        result['accuracies'] = metrics.get('accuracies', [])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def load_ig2_results(results_dir, stage, demographic, layer_quantile):\n",
    "    \"\"\"\n",
    "    Load IG² attribution results.\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'feature_scores', 'top_features', etc.\n",
    "        or None if not found\n",
    "    \"\"\"\n",
    "    # Use layer-specific filename (new format)\n",
    "    ig2_path = results_dir / stage / demographic / 'ig2' / f'{layer_quantile}_ig2_results.pt'\n",
    "    \n",
    "    # Fallback to legacy non-layer-specific path\n",
    "    if not ig2_path.exists():\n",
    "        legacy_path = results_dir / stage / demographic / 'ig2' / 'ig2_results.pt'\n",
    "        if legacy_path.exists():\n",
    "            print(f\"Warning: Using legacy IG2 file (no layer prefix): {legacy_path}\")\n",
    "            ig2_path = legacy_path\n",
    "    \n",
    "    if not ig2_path.exists():\n",
    "        raise FileNotFoundError(f\"IG² results not found: {ig2_path}\")\n",
    "    \n",
    "    data = torch.load(ig2_path, map_location='cpu')\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_sae_training_logs(results_dir, stage, sae_type, layer_quantile):\n",
    "    \"\"\"\n",
    "    Load SAE training logs.\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame with training logs\n",
    "        or None if not found\n",
    "    \"\"\"\n",
    "    log_path = results_dir / \"models\" / f\"sae-{sae_type}_{stage}_{layer_quantile}\" / \"training_logs.csv\"\n",
    "    \n",
    "    if not log_path.exists():\n",
    "        return None\n",
    "    \n",
    "    return pd.read_csv(log_path)\n",
    "\n",
    "\n",
    "print(\"Data loading functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan for available results\n",
    "available_results = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "print(\"Scanning for available results...\\n\")\n",
    "\n",
    "for demo in DEMOGRAPHICS:\n",
    "    for lq in LAYER_QUANTILES:\n",
    "        # Check probe results\n",
    "        probe_results = load_probe_results(RESULTS_DIR, STAGE, demo, lq)\n",
    "        if probe_results:\n",
    "            available_results[demo][lq]['probe'] = probe_results\n",
    "        \n",
    "        # Check IG2 results\n",
    "        ig2_results = load_ig2_results(RESULTS_DIR, STAGE, demo, lq)\n",
    "        if ig2_results:\n",
    "            available_results[demo][lq]['ig2'] = ig2_results\n",
    "\n",
    "# Check SAE training logs (SAE is shared across demographics)\n",
    "sae_logs = {}\n",
    "for lq in LAYER_QUANTILES:\n",
    "    logs = load_sae_training_logs(RESULTS_DIR, STAGE, SAE_TYPE, lq)\n",
    "    if logs is not None:\n",
    "        sae_logs[lq] = logs\n",
    "\n",
    "# Summary\n",
    "print(\"Available Results Summary:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Demographic':<15} | {'Q1 (25%)':<15} | {'Q2 (50%)':<15} | {'Q3 (75%)':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for demo in DEMOGRAPHICS:\n",
    "    row = f\"{demo:<15} |\"\n",
    "    for lq in LAYER_QUANTILES:\n",
    "        if demo in available_results and lq in available_results[demo]:\n",
    "            has_probe = 'probe' in available_results[demo][lq]\n",
    "            has_ig2 = 'ig2' in available_results[demo][lq]\n",
    "            status = f\"P:{'+' if has_probe else '-'} I:{'+' if has_ig2 else '-'}\"\n",
    "        else:\n",
    "            status = \"--\"\n",
    "        row += f\" {status:<14}|\"\n",
    "    print(row)\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\nSAE Training Logs: {', '.join(sae_logs.keys()) if sae_logs else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Probe Accuracy Comparison\n",
    "\n",
    "### How It's Computed:\n",
    "The linear probe is trained on SAE features to predict which demographic group generated each text. Accuracy = (correct predictions) / (total samples), measured on the validation set after training converges. Higher accuracy indicates SAE features successfully encode demographic-relevant information.\n",
    "\n",
    "### Analysis:\n",
    "High accuracy (near 100%) across all demographics and layers confirms that demographic bias is consistently encoded in the model's representations. Similar accuracy across layers suggests bias information persists throughout the model depth. Any demographic with lower accuracy may have more subtle or distributed bias encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect accuracy data\n",
    "accuracy_data = []\n",
    "\n",
    "for demo in DEMOGRAPHICS:\n",
    "    for lq in LAYER_QUANTILES:\n",
    "        if demo in available_results and lq in available_results[demo]:\n",
    "            if 'probe' in available_results[demo][lq]:\n",
    "                probe = available_results[demo][lq]['probe']\n",
    "                accuracy_data.append({\n",
    "                    'Demographic': demo,\n",
    "                    'Demographic_EN': DEMOGRAPHIC_EN[demo],\n",
    "                    'Layer': LAYER_LABELS[lq],\n",
    "                    'Layer_Quantile': lq,\n",
    "                    'Final_Accuracy': probe['final_accuracy'],\n",
    "                    'Best_Accuracy': probe['best_accuracy']\n",
    "                })\n",
    "\n",
    "df_accuracy = pd.DataFrame(accuracy_data)\n",
    "\n",
    "if len(df_accuracy) > 0:\n",
    "    print(f\"Collected accuracy data for {len(df_accuracy)} experiments\")\n",
    "    print(df_accuracy.head(10))\n",
    "else:\n",
    "    print(\"No accuracy data found. Please run the training pipeline first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_accuracy) > 0:\n",
    "    # Create heatmap of accuracy by demographic and layer\n",
    "    # Use English labels for the y-axis, preserve original demographic order\n",
    "    \n",
    "    # Create ordered list of English labels matching DEMOGRAPHICS order\n",
    "    demo_en_ordered = [DEMOGRAPHIC_EN[d] for d in DEMOGRAPHICS]\n",
    "    \n",
    "    pivot_acc = df_accuracy.pivot(index='Demographic_EN', columns='Layer_Quantile', values='Best_Accuracy')\n",
    "    pivot_acc = pivot_acc.reindex(demo_en_ordered)  # Reorder rows to match DEMOGRAPHICS order\n",
    "    \n",
    "    # Reorder columns\n",
    "    pivot_acc = pivot_acc[['q1', 'q2', 'q3']]\n",
    "    pivot_acc.columns = ['Q1 (25%)', 'Q2 (50%)', 'Q3 (75%)']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    sns.heatmap(\n",
    "        pivot_acc,\n",
    "        annot=True,\n",
    "        fmt='.3f',\n",
    "        cmap='RdYlGn',\n",
    "        vmin=0.0,\n",
    "        vmax=1.0,\n",
    "        ax=ax,\n",
    "        cbar_kws={'label': 'Accuracy'},\n",
    "        linewidths=0.5\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Linear Probe Accuracy (gSAE + Linear Probe)\\nby Layer and Demographic', \n",
    "                 fontsize=14, pad=15)\n",
    "    ax.set_xlabel('EXAONE Layer Quantile', fontsize=12)\n",
    "    ax.set_ylabel('Demographic Dimension', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"probe_accuracy_heatmap_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nAccuracy Statistics:\")\n",
    "    print(\"=\" * 60)\n",
    "    for lq in ['q1', 'q2', 'q3']:\n",
    "        lq_data = df_accuracy[df_accuracy['Layer_Quantile'] == lq]\n",
    "        if len(lq_data) > 0:\n",
    "            print(f\"\\n{LAYER_LABELS[lq]}:\")\n",
    "            print(f\"  Mean Accuracy:   {lq_data['Best_Accuracy'].mean():.3f}\")\n",
    "            print(f\"  Std Accuracy:    {lq_data['Best_Accuracy'].std():.3f}\")\n",
    "            print(f\"  Min Accuracy:    {lq_data['Best_Accuracy'].min():.3f}\")\n",
    "            print(f\"  Max Accuracy:    {lq_data['Best_Accuracy'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_accuracy) > 0:\n",
    "    # Grouped bar chart with English labels\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Get English labels in order\n",
    "    demographics_en = [DEMOGRAPHIC_EN[d] for d in DEMOGRAPHICS]\n",
    "    \n",
    "    x = np.arange(len(DEMOGRAPHICS))\n",
    "    width = 0.25\n",
    "    \n",
    "    colors = ['#3498db', '#2ecc71', '#e74c3c']  # Blue, Green, Red\n",
    "    \n",
    "    for i, lq in enumerate(LAYER_QUANTILES):\n",
    "        lq_data = df_accuracy[df_accuracy['Layer_Quantile'] == lq]\n",
    "        \n",
    "        # Get accuracy for each demographic (in order)\n",
    "        accuracies = []\n",
    "        for demo in DEMOGRAPHICS:\n",
    "            demo_data = lq_data[lq_data['Demographic'] == demo]\n",
    "            if len(demo_data) > 0:\n",
    "                accuracies.append(demo_data['Best_Accuracy'].values[0])\n",
    "            else:\n",
    "                accuracies.append(0)\n",
    "        \n",
    "        ax.bar(x + i * width, accuracies, width, label=LAYER_LABELS[lq], color=colors[i], alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Demographic Dimension', fontsize=12)\n",
    "    ax.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax.set_title('Linear Probe Accuracy Comparison by Layer', fontsize=14, pad=15)\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(demographics_en, rotation=45, ha='right')  # Use English labels\n",
    "    ax.legend(title='Layer', loc='upper right')\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.axhline(0.5, color='gray', linestyle='--', alpha=0.5, label='Random (50%)')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"probe_accuracy_bars_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. IG² Score Comparison\n",
    "\n",
    "### How It's Computed:\n",
    "IG² (Integrated Gradients Squared) measures each SAE feature's contribution to bias prediction by computing gradients along the path from zero to the actual feature value, then squaring and averaging. Higher IG² score means the feature is more important for the probe's demographic classification. Features above a threshold are labeled as \"bias features.\"\n",
    "\n",
    "### Analysis:\n",
    "The heatmap shows the maximum IG² score (most important bias feature) for each demographic-layer combination. Higher scores indicate more concentrated bias encoding (fewer features carry most of the signal). Variation across layers reveals where in the model bias is most strongly encoded - typically middle layers (Q2) show balanced importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect IG² statistics\n",
    "ig2_stats = []\n",
    "\n",
    "for demo in DEMOGRAPHICS:\n",
    "    for lq in LAYER_QUANTILES:\n",
    "        if demo in available_results and lq in available_results[demo]:\n",
    "            if 'ig2' in available_results[demo][lq]:\n",
    "                ig2_data = available_results[demo][lq]['ig2']\n",
    "                \n",
    "                # Get feature scores\n",
    "                if isinstance(ig2_data, dict):\n",
    "                    scores = ig2_data.get('feature_scores', ig2_data.get('ig2_scores', None))\n",
    "                else:\n",
    "                    scores = ig2_data\n",
    "                \n",
    "                if scores is not None:\n",
    "                    if isinstance(scores, torch.Tensor):\n",
    "                        scores_np = scores.cpu().numpy()\n",
    "                    else:\n",
    "                        scores_np = scores\n",
    "                    \n",
    "                    # Compute statistics\n",
    "                    top_10 = np.sort(scores_np)[-10:]\n",
    "                    top_50 = np.sort(scores_np)[-50:]\n",
    "                    top_100 = np.sort(scores_np)[-100:]\n",
    "                    \n",
    "                    # Get the index of the max score (top neuron)\n",
    "                    max_neuron_idx = int(np.argmax(scores_np))\n",
    "                    \n",
    "                    ig2_stats.append({\n",
    "                        'Demographic': demo,\n",
    "                        'Demographic_EN': DEMOGRAPHIC_EN[demo],\n",
    "                        'Layer': LAYER_LABELS[lq],\n",
    "                        'Layer_Quantile': lq,\n",
    "                        'Max_Score': scores_np.max(),\n",
    "                        'Max_Neuron_Idx': max_neuron_idx,\n",
    "                        'Top10_Mean': top_10.mean(),\n",
    "                        'Top50_Mean': top_50.mean(),\n",
    "                        'Top100_Mean': top_100.mean(),\n",
    "                        'Total_Nonzero': (scores_np > 0).sum(),\n",
    "                        'Scores': scores_np  # Keep for detailed analysis\n",
    "                    })\n",
    "\n",
    "df_ig2 = pd.DataFrame(ig2_stats)\n",
    "\n",
    "if len(df_ig2) > 0:\n",
    "    print(f\"Collected IG² data for {len(df_ig2)} experiments\")\n",
    "    print(df_ig2[['Demographic', 'Demographic_EN', 'Layer_Quantile', 'Max_Score', 'Max_Neuron_Idx', 'Top10_Mean', 'Total_Nonzero']].head(10))\n",
    "else:\n",
    "    print(\"No IG² data found. Please run the IG² computation pipeline first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_ig2) > 0:\n",
    "    # Heatmap of max IG² scores with neuron indices\n",
    "    # Use English labels for the y-axis, preserve original demographic order\n",
    "    \n",
    "    # Create ordered list of English labels matching DEMOGRAPHICS order\n",
    "    demo_en_ordered = [DEMOGRAPHIC_EN[d] for d in DEMOGRAPHICS]\n",
    "    \n",
    "    # Pivot and reindex to maintain original order\n",
    "    pivot_ig2 = df_ig2.pivot(index='Demographic_EN', columns='Layer_Quantile', values='Max_Score')\n",
    "    pivot_ig2 = pivot_ig2.reindex(demo_en_ordered)  # Reorder rows to match DEMOGRAPHICS order\n",
    "    pivot_ig2 = pivot_ig2[['q1', 'q2', 'q3']]\n",
    "    pivot_ig2.columns = ['Q1 (25%)', 'Q2 (50%)', 'Q3 (75%)']\n",
    "    \n",
    "    # Also get neuron indices for annotations\n",
    "    pivot_neuron = df_ig2.pivot(index='Demographic_EN', columns='Layer_Quantile', values='Max_Neuron_Idx')\n",
    "    pivot_neuron = pivot_neuron.reindex(demo_en_ordered)  # Same reordering\n",
    "    pivot_neuron = pivot_neuron[['q1', 'q2', 'q3']]\n",
    "    pivot_neuron.columns = ['Q1 (25%)', 'Q2 (50%)', 'Q3 (75%)']\n",
    "    \n",
    "    # Create custom annotations with score and neuron index\n",
    "    annot_labels = []\n",
    "    for idx in pivot_ig2.index:\n",
    "        row_labels = []\n",
    "        for col in pivot_ig2.columns:\n",
    "            score = pivot_ig2.loc[idx, col]\n",
    "            neuron_idx = int(pivot_neuron.loc[idx, col])\n",
    "            row_labels.append(f'{score:.4f}\\n(#{neuron_idx})')\n",
    "        annot_labels.append(row_labels)\n",
    "    annot_array = np.array(annot_labels)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "    \n",
    "    sns.heatmap(\n",
    "        pivot_ig2,\n",
    "        annot=annot_array,\n",
    "        fmt='',\n",
    "        cmap='YlOrRd',\n",
    "        ax=ax,\n",
    "        cbar_kws={'label': 'Max IG² Score'},\n",
    "        linewidths=0.5,\n",
    "        annot_kws={'fontsize': 10}\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Max IG² Score with Neuron Index (SAE Neuron Importance)\\nby Layer and Demographic', \n",
    "                 fontsize=14, pad=15)\n",
    "    ax.set_xlabel('EXAONE Layer Quantile', fontsize=12)\n",
    "    ax.set_ylabel('Demographic Dimension', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"ig2_max_scores_heatmap_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top neuron indices per demographic (in same order as heatmap)\n",
    "    print(\"\\nTop Neuron Indices (Max IG² Score) per Demographic:\")\n",
    "    print(\"=\" * 70)\n",
    "    for demo_en in demo_en_ordered:\n",
    "        demo_data = df_ig2[df_ig2['Demographic_EN'] == demo_en]\n",
    "        if len(demo_data) > 0:\n",
    "            # Get Q2 (middle layer) as representative\n",
    "            q2_data = demo_data[demo_data['Layer_Quantile'] == 'q2']\n",
    "            if len(q2_data) > 0:\n",
    "                neuron_idx = q2_data['Max_Neuron_Idx'].values[0]\n",
    "                score = q2_data['Max_Score'].values[0]\n",
    "                print(f\"  {demo_en:25s}: Neuron #{neuron_idx:5d} (IG²={score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_ig2) > 0:\n",
    "    # Top-K mean IG² scores comparison with English labels\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Create ordered list of English labels matching DEMOGRAPHICS order\n",
    "    demo_en_ordered = [DEMOGRAPHIC_EN[d] for d in DEMOGRAPHICS]\n",
    "    \n",
    "    metrics = ['Top10_Mean', 'Top50_Mean', 'Top100_Mean']\n",
    "    titles = ['Top-10 Mean IG² Score', 'Top-50 Mean IG² Score', 'Top-100 Mean IG² Score']\n",
    "    \n",
    "    for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Use English demographic labels, preserve original order\n",
    "        pivot = df_ig2.pivot(index='Demographic_EN', columns='Layer_Quantile', values=metric)\n",
    "        pivot = pivot.reindex(demo_en_ordered)  # Reorder rows to match DEMOGRAPHICS order\n",
    "        pivot = pivot[['q1', 'q2', 'q3']]\n",
    "        pivot.columns = ['Q1', 'Q2', 'Q3']\n",
    "        \n",
    "        pivot.plot(kind='bar', ax=ax, width=0.8, alpha=0.8)\n",
    "        ax.set_title(f'{title}', fontsize=12, pad=10)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('IG² Score', fontsize=11)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        ax.legend(title='Layer', loc='upper right')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('IG² Score Comparison (SAE Neuron Importance) Across Layers', \n",
    "                 fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"ig2_topk_comparison_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15-intro",
   "metadata": {},
   "source": [
    "### IG² Score Distribution\n",
    "\n",
    "This histogram shows the distribution of all non-zero IG² scores across demographics for each layer. A long-tailed distribution with few high-scoring features indicates concentrated bias encoding (good for targeted intervention). More uniform distributions suggest diffuse bias encoding across many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_ig2) > 0:\n",
    "    # Distribution of IG² scores for each layer (aggregated across demographics)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    for idx, lq in enumerate(LAYER_QUANTILES):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        lq_data = df_ig2[df_ig2['Layer_Quantile'] == lq]\n",
    "        \n",
    "        if len(lq_data) > 0:\n",
    "            # Concatenate all scores for this layer\n",
    "            all_scores = np.concatenate([row['Scores'] for _, row in lq_data.iterrows()])\n",
    "            \n",
    "            # Plot histogram (only positive scores)\n",
    "            positive_scores = all_scores[all_scores > 0]\n",
    "            ax.hist(positive_scores, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "            ax.set_xlabel('IG² Score', fontsize=11)\n",
    "            ax.set_ylabel('Frequency', fontsize=11)\n",
    "            ax.set_title(f'{LAYER_LABELS[lq]}\\n({len(positive_scores):,} non-zero features)', fontsize=12)\n",
    "            ax.set_yscale('log')\n",
    "            ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('IG² Score Distribution by Layer', fontsize=14, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"ig2_distribution_by_layer_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Training Loss Comparison\n",
    "\n",
    "### How It's Computed:\n",
    "SAE training minimizes reconstruction loss (MSE between input and reconstructed activations) plus sparsity loss (encouraging few active features). L0 sparsity counts the average number of active features per input. Linear probe training minimizes cross-entropy loss for demographic classification.\n",
    "\n",
    "### Analysis:\n",
    "Lower final reconstruction loss indicates better representation quality. Sparsity L0 around 50-200 features (out of 100K) suggests good feature selectivity. Converging probe loss confirms successful demographic encoding extraction. Similar training dynamics across layers indicates consistent optimization behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAE Training Loss Comparison\n",
    "if sae_logs:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    metrics = ['total_loss', 'recon_loss', 'sparsity_loss', 'sparsity_l0']\n",
    "    titles = ['Total Loss', 'Reconstruction Loss', 'Sparsity Loss', 'Sparsity (L0)']\n",
    "    \n",
    "    colors = {'q1': '#3498db', 'q2': '#2ecc71', 'q3': '#e74c3c'}\n",
    "    \n",
    "    for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        for lq in LAYER_QUANTILES:\n",
    "            if lq in sae_logs and metric in sae_logs[lq].columns:\n",
    "                logs = sae_logs[lq]\n",
    "                # Smooth the curve\n",
    "                window = max(1, len(logs) // 20)\n",
    "                smoothed = logs[metric].rolling(window=window, min_periods=1).mean()\n",
    "                ax.plot(logs['step'], smoothed, label=LAYER_LABELS[lq], \n",
    "                       color=colors[lq], linewidth=2, alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Training Step', fontsize=11)\n",
    "        ax.set_ylabel(title, fontsize=11)\n",
    "        ax.set_title(f'{title}', fontsize=12, pad=10)\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('SAE Training Loss Comparison by Layer', \n",
    "                 fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"sae_training_loss_comparison_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Final statistics\n",
    "    print(\"\\nSAE Final Training Statistics:\")\n",
    "    print(\"=\" * 70)\n",
    "    for lq in LAYER_QUANTILES:\n",
    "        if lq in sae_logs:\n",
    "            logs = sae_logs[lq]\n",
    "            print(f\"\\n{LAYER_LABELS[lq]}:\")\n",
    "            print(f\"  Total Steps: {len(logs)}\")\n",
    "            print(f\"  Final Total Loss: {logs['total_loss'].iloc[-1]:.4f}\")\n",
    "            print(f\"  Final Recon Loss: {logs['recon_loss'].iloc[-1]:.4f}\")\n",
    "            print(f\"  Final Sparsity L0: {logs['sparsity_l0'].iloc[-1]:.4f}\")\n",
    "else:\n",
    "    print(\"No SAE training logs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Probe Training Loss by Demographic\n",
    "probe_losses = []\n",
    "\n",
    "for demo in DEMOGRAPHICS:\n",
    "    for lq in LAYER_QUANTILES:\n",
    "        if demo in available_results and lq in available_results[demo]:\n",
    "            if 'probe' in available_results[demo][lq]:\n",
    "                probe = available_results[demo][lq]['probe']\n",
    "                if 'losses' in probe and len(probe['losses']) > 0:\n",
    "                    probe_losses.append({\n",
    "                        'Demographic': demo,\n",
    "                        'Demographic_EN': DEMOGRAPHIC_EN[demo],\n",
    "                        'Layer_Quantile': lq,\n",
    "                        'Losses': probe['losses'],\n",
    "                        'Accuracies': probe.get('accuracies', [])\n",
    "                    })\n",
    "\n",
    "if probe_losses:\n",
    "    # Select subset of demographics for clarity\n",
    "    demo_subset = DEMOGRAPHICS[:4] if len(DEMOGRAPHICS) > 4 else DEMOGRAPHICS\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors = {'q1': '#3498db', 'q2': '#2ecc71', 'q3': '#e74c3c'}\n",
    "    \n",
    "    for idx, demo in enumerate(demo_subset):\n",
    "        ax = axes[idx]\n",
    "        demo_en = DEMOGRAPHIC_EN[demo]\n",
    "        \n",
    "        for lq in LAYER_QUANTILES:\n",
    "            matching = [p for p in probe_losses if p['Demographic'] == demo and p['Layer_Quantile'] == lq]\n",
    "            if matching:\n",
    "                losses = matching[0]['Losses']\n",
    "                # Smooth\n",
    "                window = max(1, len(losses) // 20)\n",
    "                smoothed = pd.Series(losses).rolling(window=window, min_periods=1).mean()\n",
    "                ax.plot(smoothed, label=LAYER_LABELS[lq], color=colors[lq], linewidth=2, alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Epoch', fontsize=11)\n",
    "        ax.set_ylabel('Loss', fontsize=11)\n",
    "        ax.set_title(f'{demo_en}', fontsize=12, pad=10)  # Use English label only\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Linear Probe Training Loss by Demographic', \n",
    "                 fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"probe_training_loss_by_demo_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No probe training loss data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary table with English labels\n",
    "summary_data = []\n",
    "\n",
    "for demo in DEMOGRAPHICS:\n",
    "    for lq in LAYER_QUANTILES:\n",
    "        row = {\n",
    "            'Demographic': DEMOGRAPHIC_EN[demo],  # Use English label\n",
    "            'Layer': lq,\n",
    "            'Probe_Accuracy': None,\n",
    "            'IG2_Max': None,\n",
    "            'IG2_Max_Neuron': None,\n",
    "            'IG2_Top10_Mean': None,\n",
    "        }\n",
    "        \n",
    "        if demo in available_results and lq in available_results[demo]:\n",
    "            if 'probe' in available_results[demo][lq]:\n",
    "                row['Probe_Accuracy'] = available_results[demo][lq]['probe']['best_accuracy']\n",
    "            \n",
    "            if 'ig2' in available_results[demo][lq]:\n",
    "                ig2_row = df_ig2[(df_ig2['Demographic'] == demo) & (df_ig2['Layer_Quantile'] == lq)]\n",
    "                if len(ig2_row) > 0:\n",
    "                    row['IG2_Max'] = ig2_row['Max_Score'].values[0]\n",
    "                    row['IG2_Max_Neuron'] = int(ig2_row['Max_Neuron_Idx'].values[0])\n",
    "                    row['IG2_Top10_Mean'] = ig2_row['Top10_Mean'].values[0]\n",
    "        \n",
    "        summary_data.append(row)\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"COMPREHENSIVE SUMMARY TABLE\")\n",
    "print(\"=\" * 100)\n",
    "print(df_summary.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "df_summary.to_csv(ASSETS_DIR / f\"layer_demographic_summary_{STAGE}.csv\", index=False)\n",
    "print(f\"\\nSaved summary to: {ASSETS_DIR / f'layer_demographic_summary_{STAGE}.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
