{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Activation Heatmaps\n",
    "\n",
    "This notebook visualizes feature activation patterns across bias prompts.\n",
    "\n",
    "**Purpose:**\n",
    "- Show which features activate for which types of prompts\n",
    "- Identify patterns in feature activation across demographics\n",
    "- Visualize sparsity and activation magnitudes\n",
    "\n",
    "**Input Data:**\n",
    "- SAE feature activations: [N_prompts × 100,000]\n",
    "- Top bias features from IG² attribution\n",
    "\n",
    "**Output:**\n",
    "- Heatmap of activations [prompts × features]\n",
    "- Sparsity analysis\n",
    "- Clustering visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nfrom pathlib import Path\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom tqdm import tqdm\n\nPROJECT_ROOT = Path(os.getcwd()).parent.parent\nsys.path.append(str(PROJECT_ROOT))\n\nfrom src.visualization import (\n    setup_korean_font,\n    load_demographics,\n    load_ig2_results,\n    load_activations,\n    load_sae_decoder_weights,\n    plot_activation_heatmap,\n    select_top_features_union,\n    get_demographic_labels\n)\nfrom src.models.sae import GatedAutoEncoder, AutoEncoder\n\nprint(f\"Project root: {PROJECT_ROOT}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "setup_korean_font()\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nDATA_DIR = PROJECT_ROOT / \"data\"\nRESULTS_DIR = PROJECT_ROOT / \"results\"\nASSETS_DIR = PROJECT_ROOT / \"notebooks\" / \"visualizations\" / \"assets\"\nASSETS_DIR.mkdir(exist_ok=True, parents=True)\n\n# Stage: 'pilot', 'medium', or 'full'\nSTAGE = \"pilot\"\n\n# SAE configuration\nSAE_TYPE = \"gated\"  # 'standard' or 'gated'\nLAYER_QUANTILE = \"q2\"  # 'q1', 'q2', or 'q3'\n\n# Demographic to analyze (None = analyze all)\nDEMOGRAPHIC = None  # e.g., \"성별\", \"인종\", etc.\n\n# Visualization parameters\nTOP_K = 50  # Top features per demographic\n\nprint(f\"Stage: {STAGE}\")\nprint(f\"SAE type: {SAE_TYPE}\")\nprint(f\"Layer quantile: {LAYER_QUANTILE}\")\nprint(f\"Demographic: {DEMOGRAPHIC or 'all'}\")\nprint(f\"Top-K: {TOP_K}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load demographics\ndemographics_dict = load_demographics(DATA_DIR)\ndemographic_labels_ko, _ = get_demographic_labels(demographics_dict)\n\n# Load IG² results (loads from all per-demographic directories)\nig2_results = load_ig2_results(RESULTS_DIR, stage=STAGE, demographic=DEMOGRAPHIC)\n\nprint(f\"IG² results loaded for {len(ig2_results)} demographics\")\nfor demo in ig2_results.keys():\n    print(f\"  - {demo}\")"
  },
  {
   "cell_type": "markdown",
   "source": "## Load Activations and Compute SAE Features",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Load activations from pickle file\n# If DEMOGRAPHIC is specified, load from per-demographic directory\nif DEMOGRAPHIC:\n    activations, labels, prompts = load_activations(\n        RESULTS_DIR, stage=STAGE, demographic=DEMOGRAPHIC, layer_quantile=LAYER_QUANTILE\n    )\nelse:\n    # Load from first available demographic\n    first_demo = list(ig2_results.keys())[0]\n    activations, labels, prompts = load_activations(\n        RESULTS_DIR, stage=STAGE, demographic=first_demo, layer_quantile=LAYER_QUANTILE\n    )\n    print(f\"Loaded activations from demographic: {first_demo}\")\n\nprint(f\"Activations shape: {activations.shape}\")\nprint(f\"Number of samples: {len(labels)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load SAE model and compute features\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nsae_path = RESULTS_DIR / \"models\" / f\"sae-{SAE_TYPE}_{STAGE}_{LAYER_QUANTILE}\" / \"model.pth\"\n\nif not sae_path.exists():\n    raise FileNotFoundError(f\"SAE model not found at {sae_path}. Please run 03_train_sae.py first.\")\n\nprint(f\"Loading SAE from {sae_path}\")\nif SAE_TYPE == 'gated':\n    sae = GatedAutoEncoder.from_pretrained(str(sae_path))\nelse:\n    sae = AutoEncoder.from_pretrained(str(sae_path))\n\nsae.to(device)\nsae.eval()\n\nprint(f\"SAE loaded: dict_size={sae.dict_size}, activation_dim={sae.activation_dim}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Extract SAE features from activations\nn_samples = len(activations)\nfeatures = torch.zeros(n_samples, sae.dict_size)\n\nprint(f\"Extracting SAE features for {n_samples} samples...\")\n\nwith torch.no_grad():\n    for i in tqdm(range(n_samples), desc=\"Extracting features\"):\n        sample = activations[i].unsqueeze(0).to(device)\n        _, feat = sae(sample, output_features=True)\n        features[i] = feat[0].cpu()\n\n# Create prompt_ids\nprompt_ids = [f\"prompt_{i}\" for i in range(n_samples)]\n\nprint(f\"\\nFeature activations shape: {features.shape}\")\nprint(f\"Number of prompts: {len(prompt_ids)}\")\n\n# Clean up SAE from GPU memory\ndel sae\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select union of top features across demographics\n",
    "all_top_features, demographic2topfeatures = select_top_features_union(\n",
    "    ig2_results, top_k=TOP_K\n",
    ")\n",
    "\n",
    "print(f\"Total unique features selected: {len(all_top_features)}\")\n",
    "print(f\"Features per demographic: {TOP_K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Activation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap\n",
    "fig = plot_activation_heatmap(\n",
    "    feature_activations=features,\n",
    "    selected_features=all_top_features,\n",
    "    prompt_labels=[f\"P{i}\" for i in range(len(features))],\n",
    "    save_path=ASSETS_DIR / f\"activation_heatmap_{STAGE}_top{TOP_K}.png\",\n",
    "    figsize=(20, 12),\n",
    "    cmap='viridis'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.feature_selection import compute_feature_sparsity\n",
    "\n",
    "# Compute sparsity\n",
    "overall_sparsity, per_feature_sparsity = compute_feature_sparsity(features)\n",
    "\n",
    "print(f\"Overall sparsity: {overall_sparsity:.2%}\")\n",
    "print(f\"Mean per-feature sparsity: {per_feature_sparsity.mean():.2%}\")\n",
    "print(f\"Median per-feature sparsity: {per_feature_sparsity.median():.2%}\")\n",
    "\n",
    "# Plot sparsity distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of per-feature sparsity\n",
    "axes[0].hist(per_feature_sparsity.cpu().numpy(), bins=50, color='skyblue', edgecolor='black')\n",
    "axes[0].axvline(overall_sparsity, color='red', linestyle='--', label=f'Overall: {overall_sparsity:.2%}')\n",
    "axes[0].set_xlabel('Sparsity (fraction of zeros)', fontsize=12)\n",
    "axes[0].set_ylabel('Number of Features', fontsize=12)\n",
    "axes[0].set_title('특성별 희소성 분포\\nPer-Feature Sparsity Distribution', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Activation magnitude distribution (non-zero only)\n",
    "non_zero_activations = features[features > 0]\n",
    "axes[1].hist(non_zero_activations.cpu().numpy(), bins=50, color='lightcoral', edgecolor='black')\n",
    "axes[1].set_xlabel('Activation Magnitude', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('활성화 크기 분포 (0 제외)\\nActivation Magnitude Distribution (non-zero)', fontsize=14)\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ASSETS_DIR / f\"sparsity_analysis_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Activation Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute activation frequency for top features\n",
    "selected_features = features[:, all_top_features]\n",
    "activation_freq = (selected_features > 0).float().mean(dim=0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "x = np.arange(len(all_top_features))\n",
    "ax.bar(x, activation_freq.cpu().numpy(), color='seagreen', alpha=0.7)\n",
    "ax.set_xlabel('Feature Index (sorted by selection)', fontsize=12)\n",
    "ax.set_ylabel('Activation Frequency', fontsize=12)\n",
    "ax.set_title('편향 특성 활성화 빈도\\nBias Feature Activation Frequency', fontsize=14, pad=15)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add mean line\n",
    "ax.axhline(activation_freq.mean().item(), color='red', linestyle='--', \n",
    "           label=f'Mean: {activation_freq.mean():.2%}')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(ASSETS_DIR / f\"activation_frequency_{STAGE}_top{TOP_K}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nActivation Frequency Statistics:\")\n",
    "print(f\"  Mean: {activation_freq.mean():.2%}\")\n",
    "print(f\"  Median: {activation_freq.median():.2%}\")\n",
    "print(f\"  Min: {activation_freq.min():.2%}\")\n",
    "print(f\"  Max: {activation_freq.max():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustered Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster prompts by activation patterns\n",
    "n_clusters = min(5, len(features) // 10)\n",
    "\n",
    "if len(features) >= n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(selected_features.cpu().numpy())\n",
    "    \n",
    "    # Sort by cluster\n",
    "    sort_idx = np.argsort(cluster_labels)\n",
    "    sorted_features = selected_features[sort_idx]\n",
    "    sorted_labels = cluster_labels[sort_idx]\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(20, 12))\n",
    "    \n",
    "    im = ax.imshow(sorted_features.cpu().numpy(), aspect='auto', cmap='viridis', interpolation='nearest')\n",
    "    \n",
    "    # Add cluster boundaries\n",
    "    boundaries = [0]\n",
    "    for i in range(1, len(sorted_labels)):\n",
    "        if sorted_labels[i] != sorted_labels[i-1]:\n",
    "            boundaries.append(i)\n",
    "            ax.axhline(i - 0.5, color='red', linewidth=2, alpha=0.7)\n",
    "    boundaries.append(len(sorted_labels))\n",
    "    \n",
    "    # Add cluster labels\n",
    "    for i in range(len(boundaries) - 1):\n",
    "        mid = (boundaries[i] + boundaries[i+1]) / 2\n",
    "        ax.text(-5, mid, f'C{i}', va='center', ha='right', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im, ax=ax, label='Activation Magnitude')\n",
    "    ax.set_xlabel(f'Top {TOP_K} Features per Demographic', fontsize=14)\n",
    "    ax.set_ylabel('Prompts (clustered)', fontsize=14)\n",
    "    ax.set_title('클러스터된 특성 활성화 패턴\\nClustered Feature Activation Patterns', \n",
    "                 fontsize=16, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"clustered_activation_heatmap_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nClustered {len(features)} prompts into {n_clusters} groups\")\n",
    "    for i in range(n_clusters):\n",
    "        count = (cluster_labels == i).sum()\n",
    "        print(f\"  Cluster {i}: {count} prompts\")\n",
    "else:\n",
    "    print(f\"Not enough prompts for clustering (have {len(features)}, need ≥{n_clusters})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "### What to Look For:\n",
    "\n",
    "1. **Activation Patterns:**\n",
    "   - Are certain features consistently active across prompts?\n",
    "   - Are there prompt-specific feature activations?\n",
    "   - Do features cluster together in activation?\n",
    "\n",
    "2. **Sparsity:**\n",
    "   - Is the target sparsity (95-99%) achieved?\n",
    "   - Are some features more sparse than others?\n",
    "   - What is the distribution of non-zero activations?\n",
    "\n",
    "3. **Clustering:**\n",
    "   - Do prompts group by demographic dimension?\n",
    "   - Are there distinct activation profiles?\n",
    "   - Which features are shared vs. unique across clusters?\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Test manipulation effects on high-frequency features\n",
    "2. Investigate features with unusual activation patterns\n",
    "3. Correlate activation patterns with bias scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}