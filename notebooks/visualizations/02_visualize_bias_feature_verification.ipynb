{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Bias Feature Verification Analysis\n",
    "\n",
    "This notebook visualizes the results of bias feature verification tests:\n",
    "- **Suppression Test**: Setting identified bias features to 0 should reduce bias gap\n",
    "- **Amplification Test**: Multiplying bias features by 2 should increase bias gap  \n",
    "- **Random Control**: Suppressing random features should have minimal effect\n",
    "\n",
    "## Validation Criteria:\n",
    "1. Suppression reduces bias gap (negative change ratio)\n",
    "2. Amplification increases bias gap (positive change ratio)\n",
    "3. Effect is statistically significant vs random (|z-score| > 2)\n",
    "\n",
    "## Data Source:\n",
    "Results from `scripts/06_verify_bias_features.py` stored in:\n",
    "- `results/{stage}/{demographic}/verification/suppression_test.json`\n",
    "- `results/{stage}/{demographic}/verification/amplification_test.json`\n",
    "- `results/{stage}/{demographic}/verification/random_control.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.visualization import ensure_korean_font, load_verification_results\n",
    "from src.utils import load_json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Korean font\n",
    "font_name = ensure_korean_font()\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "ASSETS_DIR = PROJECT_ROOT / \"notebooks\" / \"visualizations\" / \"assets\"\n",
    "ASSETS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Stage\n",
    "STAGE = \"full\"\n",
    "\n",
    "# Load demographics\n",
    "demo_dict = load_json(DATA_DIR / \"demographic_dict_ko.json\")\n",
    "DEMOGRAPHICS = list(demo_dict.keys())\n",
    "DEMOGRAPHIC_EN = {d: demo_dict[d]['dimension_en'] for d in DEMOGRAPHICS}\n",
    "\n",
    "print(f\"Stage: {STAGE}\")\n",
    "print(f\"\\nDemographics ({len(DEMOGRAPHICS)}):\")\n",
    "for d in DEMOGRAPHICS:\n",
    "    print(f\"  - {d} ({DEMOGRAPHIC_EN[d]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_verification_data(results_dir, stage, demographic):\n",
    "    \"\"\"\n",
    "    Load all verification results for a demographic.\n",
    "    \n",
    "    Returns:\n",
    "        dict with suppression, amplification, and random control data\n",
    "    \"\"\"\n",
    "    verif_dir = results_dir / stage / demographic / 'verification'\n",
    "    \n",
    "    if not verif_dir.exists():\n",
    "        return None\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    # Load suppression test\n",
    "    suppress_path = verif_dir / 'suppression_test.json'\n",
    "    if suppress_path.exists():\n",
    "        result['suppression'] = load_json(suppress_path)\n",
    "    \n",
    "    # Load amplification test\n",
    "    amplify_path = verif_dir / 'amplification_test.json'\n",
    "    if amplify_path.exists():\n",
    "        result['amplification'] = load_json(amplify_path)\n",
    "    \n",
    "    # Load random control\n",
    "    random_path = verif_dir / 'random_control.json'\n",
    "    if random_path.exists():\n",
    "        result['random'] = load_json(random_path)\n",
    "    \n",
    "    return result if result else None\n",
    "\n",
    "\n",
    "print(\"Data loading functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all verification results\n",
    "verification_data = {}\n",
    "\n",
    "print(\"Loading verification results...\\n\")\n",
    "\n",
    "for demo in DEMOGRAPHICS:\n",
    "    data = load_verification_data(RESULTS_DIR, STAGE, demo)\n",
    "    if data:\n",
    "        verification_data[demo] = data\n",
    "        print(f\"  {demo} ({DEMOGRAPHIC_EN[demo]}): Loaded\")\n",
    "    else:\n",
    "        print(f\"  {demo} ({DEMOGRAPHIC_EN[demo]}): NOT FOUND\")\n",
    "\n",
    "print(f\"\\nTotal demographics with verification results: {len(verification_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dataframe\n",
    "summary_data = []\n",
    "\n",
    "for demo in DEMOGRAPHICS:\n",
    "    if demo not in verification_data:\n",
    "        continue\n",
    "    \n",
    "    data = verification_data[demo]\n",
    "    \n",
    "    row = {\n",
    "        'Demographic': demo,\n",
    "        'Demographic_EN': DEMOGRAPHIC_EN[demo],\n",
    "    }\n",
    "    \n",
    "    # Suppression data\n",
    "    if 'suppression' in data:\n",
    "        supp = data['suppression']\n",
    "        row['Suppress_Gap_Before'] = supp.get('gap_before', 0)\n",
    "        row['Suppress_Gap_After'] = supp.get('gap_after', 0)\n",
    "        row['Suppress_Change_Ratio'] = supp.get('gap_change_ratio', 0)\n",
    "        row['Suppress_Num_Features'] = supp.get('metadata', {}).get('num_features_manipulated', 0)\n",
    "    \n",
    "    # Amplification data\n",
    "    if 'amplification' in data:\n",
    "        amp = data['amplification']\n",
    "        row['Amplify_Gap_Before'] = amp.get('gap_before', 0)\n",
    "        row['Amplify_Gap_After'] = amp.get('gap_after', 0)\n",
    "        row['Amplify_Change_Ratio'] = amp.get('gap_change_ratio', 0)\n",
    "    \n",
    "    # Random control data\n",
    "    if 'random' in data:\n",
    "        rand = data['random']\n",
    "        row['Random_Mean_Change'] = rand.get('mean_gap_change', 0)\n",
    "        row['Random_Std_Change'] = rand.get('std_gap_change', 0)\n",
    "        row['Random_Num_Trials'] = rand.get('num_trials', 0)\n",
    "        \n",
    "        # Calculate Z-score for suppression effect\n",
    "        if row.get('Suppress_Change_Ratio') is not None and rand.get('std_gap_change', 0) > 0:\n",
    "            z_score = (row['Suppress_Change_Ratio'] - rand['mean_gap_change']) / rand['std_gap_change']\n",
    "            row['Z_Score'] = z_score\n",
    "        else:\n",
    "            row['Z_Score'] = 0\n",
    "    \n",
    "    summary_data.append(row)\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"Verification Summary:\")\n",
    "print(\"=\" * 100)\n",
    "display_cols = ['Demographic_EN', 'Suppress_Change_Ratio', 'Amplify_Change_Ratio', \n",
    "                'Random_Mean_Change', 'Z_Score', 'Suppress_Num_Features']\n",
    "print(df_summary[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Suppression vs Amplification Comparison\n",
    "\n",
    "Compare the gap change ratios for suppression and amplification across demographics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_summary) > 0:\n",
    "    # Prepare data for plotting\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Get English labels in order\n",
    "    demographics_en = df_summary['Demographic_EN'].tolist()\n",
    "    \n",
    "    # === Left: Gap Change Ratio Comparison ===\n",
    "    ax = axes[0]\n",
    "    \n",
    "    x = np.arange(len(demographics_en))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Suppression bars (should be negative for success)\n",
    "    suppress_ratios = df_summary['Suppress_Change_Ratio'].values * 100  # Convert to percentage\n",
    "    amplify_ratios = df_summary['Amplify_Change_Ratio'].values * 100  # Convert to percentage\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, suppress_ratios, width, label='Suppression', \n",
    "                   color='#3498db', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, amplify_ratios, width, label='Amplification', \n",
    "                   color='#e74c3c', alpha=0.8)\n",
    "    \n",
    "    # Reference line at 0\n",
    "    ax.axhline(y=0, color='gray', linestyle='-', linewidth=1)\n",
    "    \n",
    "    ax.set_xlabel('Demographic Dimension', fontsize=12)\n",
    "    ax.set_ylabel('Gap Change Ratio (%)', fontsize=12)\n",
    "    ax.set_title('Bias Gap Change Ratio by Manipulation Type', fontsize=14, pad=15)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(demographics_en, rotation=45, ha='right', fontsize=10)\n",
    "    ax.legend(loc='upper right', fontsize=11)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, val in zip(bars1, suppress_ratios):\n",
    "        if val != 0:\n",
    "            ax.annotate(f'{val:.1f}%', xy=(bar.get_x() + bar.get_width()/2, val),\n",
    "                       ha='center', va='bottom' if val > 0 else 'top', fontsize=8)\n",
    "    for bar, val in zip(bars2, amplify_ratios):\n",
    "        if val != 0:\n",
    "            ax.annotate(f'{val:.1f}%', xy=(bar.get_x() + bar.get_width()/2, val),\n",
    "                       ha='center', va='bottom' if val > 0 else 'top', fontsize=8)\n",
    "    \n",
    "    # === Right: Absolute Gap Values (Before/After) ===\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    gap_before = df_summary['Suppress_Gap_Before'].values\n",
    "    gap_after_suppress = df_summary['Suppress_Gap_After'].values\n",
    "    gap_after_amplify = df_summary['Amplify_Gap_After'].values\n",
    "    \n",
    "    width = 0.25\n",
    "    \n",
    "    ax2.bar(x - width, gap_before, width, label='Baseline', color='gray', alpha=0.7)\n",
    "    ax2.bar(x, gap_after_suppress, width, label='After Suppression', color='#3498db', alpha=0.8)\n",
    "    ax2.bar(x + width, gap_after_amplify, width, label='After Amplification', color='#e74c3c', alpha=0.8)\n",
    "    \n",
    "    ax2.set_xlabel('Demographic Dimension', fontsize=12)\n",
    "    ax2.set_ylabel('Logit Gap (Mean)', fontsize=12)\n",
    "    ax2.set_title('Absolute Logit Gap Values', fontsize=14, pad=15)\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(demographics_en, rotation=45, ha='right', fontsize=10)\n",
    "    ax2.legend(loc='upper right', fontsize=10)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"verification_comparison_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No verification data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Verification Effects by Demographic (Bar Charts)\n",
    "\n",
    "Detailed view of baseline, suppression, amplification, and random control for each demographic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(verification_data) > 0:\n",
    "    n_demographics = len(verification_data)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_demographics + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    fig.suptitle(\n",
    "        'Bias Feature Manipulation Effects by Demographic\\n'\n",
    "        '(Baseline / Suppression / Amplification / Random)',\n",
    "        fontsize=18,\n",
    "        y=0.995\n",
    "    )\n",
    "    \n",
    "    for i, demo in enumerate(verification_data.keys()):\n",
    "        ax = axes[i]\n",
    "        data = verification_data[demo]\n",
    "        demo_en = DEMOGRAPHIC_EN.get(demo, demo)\n",
    "        \n",
    "        # Extract values\n",
    "        baseline_gap = data.get('suppression', {}).get('gap_before', 0)\n",
    "        suppress_gap = data.get('suppression', {}).get('gap_after', 0)\n",
    "        amplify_gap = data.get('amplification', {}).get('gap_after', 0)\n",
    "        \n",
    "        # Random control - calculate gap from change ratio\n",
    "        random_mean_change = data.get('random', {}).get('mean_gap_change', 0)\n",
    "        random_gap = baseline_gap * (1 + random_mean_change)\n",
    "        \n",
    "        # Gap standard deviations\n",
    "        baseline_std = data.get('suppression', {}).get('metadata', {}).get('gap_std_before', 0)\n",
    "        suppress_std = data.get('suppression', {}).get('metadata', {}).get('gap_std_after', 0)\n",
    "        amplify_std = data.get('amplification', {}).get('metadata', {}).get('gap_std_after', 0)\n",
    "        random_std = data.get('random', {}).get('std_gap_change', 0) * baseline_gap\n",
    "        \n",
    "        # Bar data\n",
    "        x_labels = ['Baseline', 'Suppress', 'Amplify', 'Random']\n",
    "        means = [baseline_gap, suppress_gap, amplify_gap, random_gap]\n",
    "        stds = [baseline_std, suppress_std, amplify_std, random_std]\n",
    "        colors = ['gray', '#3498db', '#e74c3c', '#f39c12']\n",
    "        \n",
    "        x_pos = np.arange(len(x_labels))\n",
    "        bars = ax.bar(x_pos, means, yerr=stds, capsize=5, color=colors, alpha=0.8)\n",
    "        \n",
    "        # Baseline reference line\n",
    "        ax.axhline(y=baseline_gap, linestyle='--', color='gray', alpha=0.5, linewidth=1)\n",
    "        \n",
    "        # Labels\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(x_labels, fontsize=11)\n",
    "        ax.set_ylabel('Logit Gap', fontsize=11)\n",
    "        ax.set_title(f\"{demo}\\n({demo_en})\", fontsize=13, pad=10)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add change ratio annotations\n",
    "        suppress_change = data.get('suppression', {}).get('gap_change_ratio', 0) * 100\n",
    "        amplify_change = data.get('amplification', {}).get('gap_change_ratio', 0) * 100\n",
    "        \n",
    "        if suppress_change != 0:\n",
    "            color = 'green' if suppress_change < 0 else 'red'\n",
    "            ax.annotate(f'{suppress_change:+.1f}%', xy=(1, suppress_gap),\n",
    "                       ha='center', va='bottom', fontsize=9, color=color, fontweight='bold')\n",
    "        if amplify_change != 0:\n",
    "            color = 'red' if amplify_change > 0 else 'green'\n",
    "            ax.annotate(f'{amplify_change:+.1f}%', xy=(2, amplify_gap),\n",
    "                       ha='center', va='bottom', fontsize=9, color=color, fontweight='bold')\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for i in range(len(verification_data), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"verification_effects_by_demo_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No verification data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Statistical Significance Analysis (Z-Score)\n",
    "\n",
    "Compare suppression effect vs random control to assess statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_summary) > 0 and 'Z_Score' in df_summary.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    demographics_en = df_summary['Demographic_EN'].tolist()\n",
    "    z_scores = df_summary['Z_Score'].values\n",
    "    \n",
    "    # === Left: Z-Score Bar Chart ===\n",
    "    ax = axes[0]\n",
    "    \n",
    "    colors = ['#27ae60' if abs(z) > 2 else '#e74c3c' for z in z_scores]\n",
    "    \n",
    "    x = np.arange(len(demographics_en))\n",
    "    bars = ax.bar(x, z_scores, color=colors, alpha=0.8)\n",
    "    \n",
    "    # Significance thresholds\n",
    "    ax.axhline(y=2, color='gray', linestyle='--', linewidth=1.5, alpha=0.7, label='p < 0.05 threshold')\n",
    "    ax.axhline(y=-2, color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    ax.set_xlabel('Demographic Dimension', fontsize=12)\n",
    "    ax.set_ylabel('Z-Score', fontsize=12)\n",
    "    ax.set_title('Statistical Significance of Suppression Effect\\n(vs Random Control)', fontsize=14, pad=15)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(demographics_en, rotation=45, ha='right', fontsize=10)\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, z_scores):\n",
    "        ax.annotate(f'{val:.2f}', xy=(bar.get_x() + bar.get_width()/2, val),\n",
    "                   ha='center', va='bottom' if val > 0 else 'top', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # === Right: Suppression vs Random Comparison ===\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    suppress_changes = df_summary['Suppress_Change_Ratio'].values * 100\n",
    "    random_changes = df_summary['Random_Mean_Change'].values * 100\n",
    "    random_stds = df_summary['Random_Std_Change'].values * 100\n",
    "    \n",
    "    width = 0.35\n",
    "    \n",
    "    ax2.bar(x - width/2, suppress_changes, width, label='Suppression Effect', \n",
    "            color='#3498db', alpha=0.8)\n",
    "    ax2.bar(x + width/2, random_changes, width, yerr=random_stds, capsize=3,\n",
    "            label='Random Control (mean +/- std)', color='#f39c12', alpha=0.8)\n",
    "    \n",
    "    ax2.axhline(y=0, color='gray', linestyle='-', linewidth=1)\n",
    "    \n",
    "    ax2.set_xlabel('Demographic Dimension', fontsize=12)\n",
    "    ax2.set_ylabel('Gap Change Ratio (%)', fontsize=12)\n",
    "    ax2.set_title('Suppression Effect vs Random Control', fontsize=14, pad=15)\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(demographics_en, rotation=45, ha='right', fontsize=10)\n",
    "    ax2.legend(loc='upper right', fontsize=10)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"verification_zscore_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print significance summary\n",
    "    significant = df_summary[abs(df_summary['Z_Score']) > 2]\n",
    "    print(f\"\\nStatistically Significant Demographics (|z| > 2): {len(significant)}/{len(df_summary)}\")\n",
    "    for _, row in significant.iterrows():\n",
    "        print(f\"  - {row['Demographic_EN']}: z = {row['Z_Score']:.2f}\")\n",
    "else:\n",
    "    print(\"No Z-score data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Heatmap Visualization\n",
    "\n",
    "Comprehensive heatmaps for verification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_summary) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
    "    \n",
    "    # Prepare data with English labels as index\n",
    "    df_heatmap = df_summary.set_index('Demographic_EN')\n",
    "    \n",
    "    # === Left: Gap Change Ratios Heatmap ===\n",
    "    ax = axes[0]\n",
    "    \n",
    "    change_cols = ['Suppress_Change_Ratio', 'Amplify_Change_Ratio', 'Random_Mean_Change']\n",
    "    if all(col in df_heatmap.columns for col in change_cols):\n",
    "        change_data = df_heatmap[change_cols].copy() * 100  # Convert to percentage\n",
    "        change_data.columns = ['Suppression', 'Amplification', 'Random']\n",
    "        \n",
    "        # Create custom colormap: blue (negative) - white (0) - red (positive)\n",
    "        sns.heatmap(\n",
    "            change_data,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cmap='RdBu_r',\n",
    "            center=0,\n",
    "            ax=ax,\n",
    "            cbar_kws={'label': 'Gap Change (%)'},\n",
    "            linewidths=0.5,\n",
    "            annot_kws={'fontsize': 11}\n",
    "        )\n",
    "        \n",
    "        ax.set_title('Gap Change Ratio (%)\\n(Negative = Bias Reduced)', fontsize=14, pad=15)\n",
    "        ax.set_xlabel('Manipulation Type', fontsize=12)\n",
    "        ax.set_ylabel('Demographic', fontsize=12)\n",
    "    \n",
    "    # === Right: Absolute Gap Values ===\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    gap_cols = ['Suppress_Gap_Before', 'Suppress_Gap_After', 'Amplify_Gap_After']\n",
    "    if all(col in df_heatmap.columns for col in gap_cols):\n",
    "        gap_data = df_heatmap[gap_cols].copy()\n",
    "        gap_data.columns = ['Baseline', 'After Suppress', 'After Amplify']\n",
    "        \n",
    "        sns.heatmap(\n",
    "            gap_data,\n",
    "            annot=True,\n",
    "            fmt='.4f',\n",
    "            cmap='YlOrRd',\n",
    "            ax=ax2,\n",
    "            cbar_kws={'label': 'Logit Gap'},\n",
    "            linewidths=0.5,\n",
    "            annot_kws={'fontsize': 11}\n",
    "        )\n",
    "        \n",
    "        ax2.set_title('Absolute Logit Gap Values', fontsize=14, pad=15)\n",
    "        ax2.set_xlabel('Condition', fontsize=12)\n",
    "        ax2.set_ylabel('Demographic', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"verification_heatmaps_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available for heatmap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Validation Criteria Summary\n",
    "\n",
    "Check which demographics pass all three validation criteria:\n",
    "1. Suppression reduces bias gap (gap_change_ratio < 0)\n",
    "2. Amplification increases bias gap (gap_change_ratio > 0)\n",
    "3. Effect is statistically significant vs random (|z-score| > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_summary) > 0:\n",
    "    # Compute validation criteria\n",
    "    df_validation = df_summary.copy()\n",
    "    \n",
    "    # Criterion 1: Suppression reduces bias (change ratio < 0)\n",
    "    df_validation['C1_Suppress_Reduces'] = df_validation['Suppress_Change_Ratio'] < 0\n",
    "    \n",
    "    # Criterion 2: Amplification increases bias (change ratio > 0)\n",
    "    df_validation['C2_Amplify_Increases'] = df_validation['Amplify_Change_Ratio'] > 0\n",
    "    \n",
    "    # Criterion 3: Statistically significant (|z| > 2)\n",
    "    df_validation['C3_Significant'] = abs(df_validation['Z_Score']) > 2\n",
    "    \n",
    "    # Count criteria met\n",
    "    df_validation['Criteria_Met'] = (\n",
    "        df_validation['C1_Suppress_Reduces'].astype(int) +\n",
    "        df_validation['C2_Amplify_Increases'].astype(int) +\n",
    "        df_validation['C3_Significant'].astype(int)\n",
    "    )\n",
    "    \n",
    "    # Create visual summary\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Prepare data for heatmap\n",
    "    criteria_cols = ['C1_Suppress_Reduces', 'C2_Amplify_Increases', 'C3_Significant']\n",
    "    criteria_labels = ['Suppression\\nReduces Bias', 'Amplification\\nIncreases Bias', 'Statistically\\nSignificant']\n",
    "    \n",
    "    criteria_data = df_validation.set_index('Demographic_EN')[criteria_cols].astype(int)\n",
    "    criteria_data.columns = criteria_labels\n",
    "    \n",
    "    # Custom colormap: red (fail) / green (pass)\n",
    "    cmap = sns.color_palette(['#e74c3c', '#27ae60'], as_cmap=True)\n",
    "    \n",
    "    sns.heatmap(\n",
    "        criteria_data,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap=cmap,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        ax=ax,\n",
    "        cbar=False,\n",
    "        linewidths=1,\n",
    "        annot_kws={'fontsize': 14, 'fontweight': 'bold'}\n",
    "    )\n",
    "    \n",
    "    # Replace 0/1 with symbols\n",
    "    for text in ax.texts:\n",
    "        if text.get_text() == '1':\n",
    "            text.set_text('PASS')\n",
    "            text.set_color('white')\n",
    "        else:\n",
    "            text.set_text('FAIL')\n",
    "            text.set_color('white')\n",
    "    \n",
    "    # Add criteria met count as additional column\n",
    "    criteria_met = df_validation.set_index('Demographic_EN')['Criteria_Met'].values\n",
    "    \n",
    "    ax.set_title('Validation Criteria Summary\\n(0 = FAIL, 1 = PASS)', fontsize=16, pad=20)\n",
    "    ax.set_xlabel('Validation Criterion', fontsize=13)\n",
    "    ax.set_ylabel('Demographic', fontsize=13)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"verification_validation_summary_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print text summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"VALIDATION SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for _, row in df_validation.iterrows():\n",
    "        demo = row['Demographic_EN']\n",
    "        c1 = 'PASS' if row['C1_Suppress_Reduces'] else 'FAIL'\n",
    "        c2 = 'PASS' if row['C2_Amplify_Increases'] else 'FAIL'\n",
    "        c3 = 'PASS' if row['C3_Significant'] else 'FAIL'\n",
    "        total = row['Criteria_Met']\n",
    "        \n",
    "        status = 'ALL PASS' if total == 3 else f'{total}/3'\n",
    "        print(f\"\\n{demo}:\")\n",
    "        print(f\"  [{'x' if row['C1_Suppress_Reduces'] else ' '}] Suppression reduces bias (change: {row['Suppress_Change_Ratio']*100:.2f}%)\")\n",
    "        print(f\"  [{'x' if row['C2_Amplify_Increases'] else ' '}] Amplification increases bias (change: {row['Amplify_Change_Ratio']*100:.2f}%)\")\n",
    "        print(f\"  [{'x' if row['C3_Significant'] else ' '}] Statistically significant (z-score: {row['Z_Score']:.2f})\")\n",
    "        print(f\"  => Status: {status}\")\n",
    "    \n",
    "    # Overall summary\n",
    "    all_pass = len(df_validation[df_validation['Criteria_Met'] == 3])\n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(f\"OVERALL: {all_pass}/{len(df_validation)} demographics pass all criteria\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"No data available for validation summary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Feature Indices Analysis\n",
    "\n",
    "Analyze the bias feature indices that were manipulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(verification_data) > 0:\n",
    "    # Collect feature indices for each demographic\n",
    "    feature_data = []\n",
    "    all_feature_indices = {}\n",
    "    \n",
    "    for demo in verification_data.keys():\n",
    "        data = verification_data[demo]\n",
    "        if 'suppression' in data:\n",
    "            feature_indices = data['suppression'].get('feature_indices', [])\n",
    "            all_feature_indices[demo] = feature_indices\n",
    "            \n",
    "            feature_data.append({\n",
    "                'Demographic': demo,\n",
    "                'Demographic_EN': DEMOGRAPHIC_EN.get(demo, demo),\n",
    "                'Num_Features': len(feature_indices),\n",
    "                'Min_Index': min(feature_indices) if feature_indices else 0,\n",
    "                'Max_Index': max(feature_indices) if feature_indices else 0,\n",
    "                'Mean_Index': np.mean(feature_indices) if feature_indices else 0\n",
    "            })\n",
    "    \n",
    "    df_features = pd.DataFrame(feature_data)\n",
    "    \n",
    "    print(\"Bias Feature Indices Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df_features.to_string(index=False))\n",
    "    \n",
    "    # Visualize number of features per demographic\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bar chart of feature counts\n",
    "    ax = axes[0]\n",
    "    x = np.arange(len(df_features))\n",
    "    ax.bar(x, df_features['Num_Features'].values, color='steelblue', alpha=0.8)\n",
    "    ax.set_xlabel('Demographic', fontsize=12)\n",
    "    ax.set_ylabel('Number of Bias Features', fontsize=12)\n",
    "    ax.set_title('Number of Identified Bias Features per Demographic', fontsize=14, pad=15)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df_features['Demographic_EN'].values, rotation=45, ha='right', fontsize=10)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(df_features['Num_Features'].values):\n",
    "        ax.text(i, v + 0.5, str(v), ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Feature index distribution\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Combine all feature indices\n",
    "    all_indices = []\n",
    "    for indices in all_feature_indices.values():\n",
    "        all_indices.extend(indices)\n",
    "    \n",
    "    if all_indices:\n",
    "        ax2.hist(all_indices, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "        ax2.set_xlabel('Feature Index', fontsize=12)\n",
    "        ax2.set_ylabel('Frequency', fontsize=12)\n",
    "        ax2.set_title('Distribution of Bias Feature Indices\\n(Across All Demographics)', fontsize=14, pad=15)\n",
    "        ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"verification_feature_analysis_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature overlap analysis\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Feature Overlap Analysis:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Count feature frequency across demographics\n",
    "    from collections import Counter\n",
    "    feature_counts = Counter(all_indices)\n",
    "    \n",
    "    # Find features shared across multiple demographics\n",
    "    shared_features = {f: c for f, c in feature_counts.items() if c > 1}\n",
    "    print(f\"\\nTotal unique features: {len(feature_counts)}\")\n",
    "    print(f\"Features shared across 2+ demographics: {len(shared_features)}\")\n",
    "    \n",
    "    if shared_features:\n",
    "        print(\"\\nTop 10 most shared features:\")\n",
    "        for feat, count in sorted(shared_features.items(), key=lambda x: -x[1])[:10]:\n",
    "            print(f\"  Feature #{feat}: shared across {count} demographics\")\n",
    "else:\n",
    "    print(\"No verification data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Export Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_summary) > 0:\n",
    "    # Create final summary table\n",
    "    final_summary = df_summary[[\n",
    "        'Demographic', 'Demographic_EN',\n",
    "        'Suppress_Gap_Before', 'Suppress_Gap_After', 'Suppress_Change_Ratio',\n",
    "        'Amplify_Gap_After', 'Amplify_Change_Ratio',\n",
    "        'Random_Mean_Change', 'Random_Std_Change', 'Z_Score',\n",
    "        'Suppress_Num_Features'\n",
    "    ]].copy()\n",
    "    \n",
    "    # Add validation columns\n",
    "    final_summary['C1_Suppress_Reduces'] = final_summary['Suppress_Change_Ratio'] < 0\n",
    "    final_summary['C2_Amplify_Increases'] = final_summary['Amplify_Change_Ratio'] > 0\n",
    "    final_summary['C3_Significant'] = abs(final_summary['Z_Score']) > 2\n",
    "    final_summary['All_Criteria_Pass'] = (\n",
    "        final_summary['C1_Suppress_Reduces'] & \n",
    "        final_summary['C2_Amplify_Increases'] & \n",
    "        final_summary['C3_Significant']\n",
    "    )\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = ASSETS_DIR / f\"verification_summary_{STAGE}.csv\"\n",
    "    final_summary.to_csv(output_path, index=False)\n",
    "    print(f\"Summary saved to: {output_path}\")\n",
    "    \n",
    "    # Display final table\n",
    "    print(\"\\nFinal Verification Summary:\")\n",
    "    print(\"=\" * 120)\n",
    "    display_summary = final_summary[[\n",
    "        'Demographic_EN', \n",
    "        'Suppress_Change_Ratio', 'Amplify_Change_Ratio',\n",
    "        'Z_Score', 'Suppress_Num_Features', 'All_Criteria_Pass'\n",
    "    ]].copy()\n",
    "    display_summary['Suppress_Change_Ratio'] = display_summary['Suppress_Change_Ratio'].apply(lambda x: f\"{x*100:.2f}%\")\n",
    "    display_summary['Amplify_Change_Ratio'] = display_summary['Amplify_Change_Ratio'].apply(lambda x: f\"{x*100:.2f}%\")\n",
    "    display_summary['Z_Score'] = display_summary['Z_Score'].apply(lambda x: f\"{x:.2f}\")\n",
    "    display_summary.columns = ['Demographic', 'Suppress Change', 'Amplify Change', 'Z-Score', 'Num Features', 'All Pass']\n",
    "    print(display_summary.to_string(index=False))\n",
    "else:\n",
    "    print(\"No data available for export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Verification Visualization Complete!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nAssets saved to: {ASSETS_DIR}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "for f in sorted(ASSETS_DIR.glob(f\"verification*_{STAGE}*\")):\n",
    "    print(f\"  - {f.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
