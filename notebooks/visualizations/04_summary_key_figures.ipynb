{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Summary: Key Figures for Korean Bias SAE Analysis\n\nThis notebook extracts and consolidates the most important visualizations from the analysis pipeline:\n\n## Figures Included:\n\n0. **Linear Probe Accuracy** (from 01_visualize_layer_demographic_comparison.ipynb)\n   - **Justification for probing approach**: High accuracy confirms SAE features encode demographic information\n   - Heatmap showing probe accuracy by layer and demographic\n\n1. **IG² Score Comparison with Statistics Table** (from 01_visualize_layer_demographic_comparison.ipynb)\n   - Heatmap showing max IG² scores with neuron indices for each demographic-layer combination\n   - Statistics table with summary metrics\n\n2. **Distribution of IG² Scores by Layer** (from 01_visualize_layer_demographic_comparison.ipynb)\n   - Histograms showing score distribution aggregated across demographics\n\n3. **Verification Heatmaps** (from 02_visualize_bias_feature_verification.ipynb)\n   - Suppression effect (bias reduction when features zeroed)\n   - Amplification effect (bias increase when features doubled)\n   - Z-score statistical significance\n\n4. **Feature Overlap Between Demographics** (from 03_analyze_important_neurons.ipynb)\n   - Jaccard similarity heatmaps showing feature sharing at 99th percentile\n\n5. **Feature Sharing Distribution** (deeper analysis of Figure 4)\n   - Bar chart showing unique vs. shared features across demographics\n   - Reveals whether bias encoding is demographic-specific or uses common mechanisms\n\n## Data Source:\n- Results from `results/full/{demographic}/` directories\n- IG² scores, verification tests, and probe accuracy metrics"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.visualization import ensure_korean_font\n",
    "from src.utils import load_json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Korean font\n",
    "font_name = ensure_korean_font()\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "ASSETS_DIR = PROJECT_ROOT / \"notebooks\" / \"visualizations\" / \"assets\"\n",
    "ASSETS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Stage\n",
    "STAGE = \"full\"\n",
    "\n",
    "# Layer quantiles to compare\n",
    "LAYER_QUANTILES = [\"q1\", \"q2\", \"q3\"]\n",
    "LAYER_LABELS = {\n",
    "    \"q1\": \"Layer 8\",\n",
    "    \"q2\": \"Layer 16\",\n",
    "    \"q3\": \"Layer 24\"\n",
    "}\n",
    "\n",
    "# Load demographics\n",
    "demo_dict = load_json(DATA_DIR / \"demographic_dict_ko.json\")\n",
    "DEMOGRAPHICS = list(demo_dict.keys())\n",
    "DEMOGRAPHIC_EN = {d: demo_dict[d]['dimension_en'] for d in DEMOGRAPHICS}\n",
    "\n",
    "print(f\"Stage: {STAGE}\")\n",
    "print(f\"Layer Quantiles: {LAYER_QUANTILES}\")\n",
    "print(f\"\\nDemographics ({len(DEMOGRAPHICS)}):\")\n",
    "for d in DEMOGRAPHICS:\n",
    "    print(f\"  - {d} ({DEMOGRAPHIC_EN[d]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "def load_probe_results(results_dir, stage, demographic, layer_quantile):\n    \"\"\"\n    Load linear probe training results.\n    \n    Returns:\n        dict with 'accuracy', 'best_accuracy', 'losses', etc.\n        or None if not found\n    \"\"\"\n    # Use layer-specific filename (new format)\n    probe_path = results_dir / stage / demographic / 'probe' / f'{layer_quantile}_linear_probe.pt'\n    metrics_path = results_dir / stage / demographic / 'probe' / f'{layer_quantile}_training_metrics.pkl'\n    \n    # Fallback to legacy non-layer-specific path\n    if not probe_path.exists():\n        probe_path = results_dir / stage / demographic / 'probe' / 'linear_probe.pt'\n        metrics_path = results_dir / stage / demographic / 'probe' / 'training_metrics.pkl'\n    \n    if not probe_path.exists():\n        return None\n    \n    result = {}\n    \n    # Load probe checkpoint\n    checkpoint = torch.load(probe_path, map_location='cpu')\n    result['final_accuracy'] = checkpoint.get('final_accuracy', 0)\n    result['best_accuracy'] = checkpoint.get('best_accuracy', 0)\n    result['layer_quantile'] = checkpoint.get('layer_quantile', layer_quantile)\n    \n    # Load training metrics if available\n    if metrics_path.exists():\n        with open(metrics_path, 'rb') as f:\n            metrics = pickle.load(f)\n        result['losses'] = metrics.get('losses', [])\n        result['accuracies'] = metrics.get('accuracies', [])\n    \n    return result\n\n\ndef load_ig2_results(results_dir, stage, demographic, layer_quantile):\n    \"\"\"\n    Load IG² attribution results.\n    \n    Returns:\n        dict with 'feature_scores', 'top_features', etc.\n        or None if not found\n    \"\"\"\n    # Use layer-specific filename (new format)\n    ig2_path = results_dir / stage / demographic / 'ig2' / f'{layer_quantile}_ig2_results.pt'\n    \n    # Fallback to legacy non-layer-specific path\n    if not ig2_path.exists():\n        legacy_path = results_dir / stage / demographic / 'ig2' / 'ig2_results.pt'\n        if legacy_path.exists():\n            print(f\"Warning: Using legacy IG2 file (no layer prefix): {legacy_path}\")\n            ig2_path = legacy_path\n    \n    if not ig2_path.exists():\n        raise FileNotFoundError(f\"IG² results not found: {ig2_path}\")\n    \n    data = torch.load(ig2_path, map_location='cpu')\n    return data\n\n\ndef load_verification_data(results_dir, stage, demographic, layer_quantile):\n    \"\"\"\n    Load verification results for a specific demographic and layer.\n    \n    Supports both:\n    - New structure: results/{stage}/{demographic}/verification/{layer_quantile}/\n    - Legacy structure: results/{stage}/{demographic}/verification/\n    \n    Returns:\n        dict with suppression, amplification, and random control data\n        or None if not found\n    \"\"\"\n    # Try new layer-specific structure first\n    verif_dir = results_dir / stage / demographic / 'verification' / layer_quantile\n    \n    # Fallback to legacy structure (no layer subdirectory)\n    if not verif_dir.exists():\n        verif_dir = results_dir / stage / demographic / 'verification'\n        if not verif_dir.exists():\n            return None\n    \n    result = {'layer_quantile': layer_quantile}\n    \n    # Load suppression test\n    suppress_path = verif_dir / 'suppression_test.json'\n    if suppress_path.exists():\n        result['suppression'] = load_json(suppress_path)\n    \n    # Load amplification test\n    amplify_path = verif_dir / 'amplification_test.json'\n    if amplify_path.exists():\n        result['amplification'] = load_json(amplify_path)\n    \n    # Load random control\n    random_path = verif_dir / 'random_control.json'\n    if random_path.exists():\n        result['random'] = load_json(random_path)\n    \n    return result if len(result) > 1 else None\n\n\nprint(\"Data loading functions defined.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# Load all probe results\nprobe_data = defaultdict(lambda: defaultdict(dict))\n\nprint(\"Loading probe results...\\n\")\n\nfor demo in DEMOGRAPHICS:\n    for lq in LAYER_QUANTILES:\n        data = load_probe_results(RESULTS_DIR, STAGE, demo, lq)\n        if data:\n            probe_data[demo][lq] = data\n\n# Load all IG² results\nig2_data = {}\n\nprint(\"Loading IG² results...\\n\")\n\nfor demo in DEMOGRAPHICS:\n    ig2_data[demo] = {}\n    for lq in LAYER_QUANTILES:\n        try:\n            data = load_ig2_results(RESULTS_DIR, STAGE, demo, lq)\n            if data is not None:\n                ig2_data[demo][lq] = data\n        except FileNotFoundError:\n            pass\n\n# Load all verification results\nverification_data = defaultdict(lambda: defaultdict(dict))\n\nprint(\"Loading verification results...\\n\")\n\nfor demo in DEMOGRAPHICS:\n    for lq in LAYER_QUANTILES:\n        data = load_verification_data(RESULTS_DIR, STAGE, demo, lq)\n        if data:\n            verification_data[demo][lq] = data\n\nprint(\"Data loading complete.\")"
  },
  {
   "cell_type": "markdown",
   "id": "jvy96cn19i",
   "source": "---\n# Figure 0: Linear Probe Accuracy (Justification for Probing Approach)\n\n## How It's Computed:\nThe linear probe is trained on SAE features to predict which demographic group generated each text. Accuracy = (correct predictions) / (total samples), measured on the validation set after training converges. Higher accuracy indicates SAE features successfully encode demographic-relevant information.\n\n## Why This Matters:\n**This figure justifies using the probing approach.** If the linear probe can accurately classify demographics based on SAE features, it confirms that:\n1. The SAE has learned meaningful representations that capture demographic information\n2. The probe's weights can be used with IG² to identify which specific features encode this information\n3. The subsequent feature manipulation experiments (suppression/amplification) are grounded in features that demonstrably relate to demographic encoding\n\n## Analysis:\nHigh accuracy (near 100%) across all demographics and layers confirms that demographic bias is consistently encoded in the model's representations. Similar accuracy across layers suggests bias information persists throughout the model depth. Any demographic with lower accuracy may have more subtle or distributed bias encoding.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "8pssny5nijy",
   "source": "# Collect accuracy data\naccuracy_data = []\n\nfor demo in DEMOGRAPHICS:\n    for lq in LAYER_QUANTILES:\n        if demo in probe_data and lq in probe_data[demo]:\n            probe = probe_data[demo][lq]\n            accuracy_data.append({\n                'Demographic': demo,\n                'Demographic_EN': DEMOGRAPHIC_EN[demo],\n                'Layer': LAYER_LABELS[lq],\n                'Layer_Quantile': lq,\n                'Final_Accuracy': probe['final_accuracy'],\n                'Best_Accuracy': probe['best_accuracy']\n            })\n\ndf_accuracy = pd.DataFrame(accuracy_data)\n\nif len(df_accuracy) > 0:\n    print(f\"Collected accuracy data for {len(df_accuracy)} experiments\")\n    print(df_accuracy.head(10))\nelse:\n    print(\"No accuracy data found. Please run the training pipeline first.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "gne6z7nxl4o",
   "source": "if len(df_accuracy) > 0:\n    # Create heatmap of accuracy by demographic and layer\n    # Use English labels for the y-axis, preserve original demographic order\n    \n    # Create ordered list of English labels matching DEMOGRAPHICS order\n    demo_en_ordered = [DEMOGRAPHIC_EN[d] for d in DEMOGRAPHICS]\n    \n    pivot_acc = df_accuracy.pivot(index='Demographic_EN', columns='Layer_Quantile', values='Best_Accuracy')\n    pivot_acc = pivot_acc.reindex(demo_en_ordered)  # Reorder rows to match DEMOGRAPHICS order\n    \n    # Reorder columns\n    pivot_acc = pivot_acc[['q1', 'q2', 'q3']]\n    pivot_acc.columns = ['Layer 8', 'Layer 16', 'Layer 24']\n    \n    fig, ax = plt.subplots(figsize=(10, 8))\n    \n    sns.heatmap(\n        pivot_acc,\n        annot=True,\n        fmt='.3f',\n        cmap='RdYlGn',\n        vmin=0.0,\n        vmax=1.0,\n        ax=ax,\n        cbar_kws={'label': 'Accuracy'},\n        linewidths=0.5\n    )\n    \n    ax.set_title('Figure 0: Linear Probe Accuracy (gSAE + Linear Probe)\\nJustification for Probing Approach', \n                 fontsize=14, pad=15)\n    ax.set_xlabel('EXAONE Layer', fontsize=12)\n    ax.set_ylabel('Demographic Dimension', fontsize=12)\n    \n    plt.tight_layout()\n    plt.savefig(ASSETS_DIR / f\"fig0_probe_accuracy_heatmap_{STAGE}.png\", dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    # Print statistics\n    print(\"\\nProbe Accuracy Statistics:\")\n    print(\"=\" * 60)\n    for lq in ['q1', 'q2', 'q3']:\n        lq_data = df_accuracy[df_accuracy['Layer_Quantile'] == lq]\n        if len(lq_data) > 0:\n            print(f\"\\n{LAYER_LABELS[lq]}:\")\n            print(f\"  Mean Accuracy:   {lq_data['Best_Accuracy'].mean():.3f}\")\n            print(f\"  Std Accuracy:    {lq_data['Best_Accuracy'].std():.3f}\")\n            print(f\"  Min Accuracy:    {lq_data['Best_Accuracy'].min():.3f}\")\n            print(f\"  Max Accuracy:    {lq_data['Best_Accuracy'].max():.3f}\")\n    \n    # Overall summary\n    print(\"\\n\" + \"=\" * 60)\n    print(\"CONCLUSION: High probe accuracy across all demographics and layers\")\n    print(\"validates that SAE features successfully encode demographic information,\")\n    print(\"justifying the use of probing for bias feature identification.\")\n    print(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "# Figure 1: IG² Score Comparison with Statistics Table\n",
    "\n",
    "## How It's Computed:\n",
    "IG² (Integrated Gradients Squared) measures each SAE feature's contribution to bias prediction by computing gradients along the path from zero to the actual feature value, then squaring and averaging. Higher IG² score means the feature is more important for the probe's demographic classification. Features above a threshold are labeled as \"bias features.\"\n",
    "\n",
    "## Analysis:\n",
    "The heatmap shows the maximum IG² score (most important bias feature) for each demographic-layer combination, along with the neuron index. Higher scores indicate more concentrated bias encoding (fewer features carry most of the signal). Variation across layers reveals where in the model bias is most strongly encoded - typically middle layers (Q2) show balanced importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect IG² statistics\n",
    "ig2_stats = []\n",
    "\n",
    "for demo in DEMOGRAPHICS:\n",
    "    for lq in LAYER_QUANTILES:\n",
    "        if lq in ig2_data[demo]:\n",
    "            data = ig2_data[demo][lq]\n",
    "            \n",
    "            # Get feature scores\n",
    "            if isinstance(data, dict):\n",
    "                scores = data.get('feature_scores', data.get('ig2_scores', None))\n",
    "            else:\n",
    "                scores = data\n",
    "            \n",
    "            if scores is not None:\n",
    "                if isinstance(scores, torch.Tensor):\n",
    "                    scores_np = scores.cpu().numpy()\n",
    "                else:\n",
    "                    scores_np = scores\n",
    "                \n",
    "                # Compute statistics\n",
    "                top_10 = np.sort(scores_np)[-10:]\n",
    "                top_50 = np.sort(scores_np)[-50:]\n",
    "                top_100 = np.sort(scores_np)[-100:]\n",
    "                \n",
    "                # Get the index of the max score (top neuron)\n",
    "                max_neuron_idx = int(np.argmax(scores_np))\n",
    "                \n",
    "                ig2_stats.append({\n",
    "                    'Demographic': demo,\n",
    "                    'Demographic_EN': DEMOGRAPHIC_EN[demo],\n",
    "                    'Layer': LAYER_LABELS[lq],\n",
    "                    'Layer_Quantile': lq,\n",
    "                    'Max_Score': scores_np.max(),\n",
    "                    'Max_Neuron_Idx': max_neuron_idx,\n",
    "                    'Top10_Mean': top_10.mean(),\n",
    "                    'Top50_Mean': top_50.mean(),\n",
    "                    'Top100_Mean': top_100.mean(),\n",
    "                    'Total_Nonzero': (scores_np > 0).sum(),\n",
    "                    'Scores': scores_np  # Keep for detailed analysis\n",
    "                })\n",
    "\n",
    "df_ig2 = pd.DataFrame(ig2_stats)\n",
    "\n",
    "if len(df_ig2) > 0:\n",
    "    print(f\"Collected IG² data for {len(df_ig2)} experiments\")\n",
    "    print(df_ig2[['Demographic', 'Demographic_EN', 'Layer_Quantile', 'Max_Score', 'Max_Neuron_Idx', 'Top10_Mean', 'Total_Nonzero']].head(10))\n",
    "else:\n",
    "    print(\"No IG² data found. Please run the IG² computation pipeline first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_ig2) > 0:\n",
    "    # Heatmap of max IG² scores with neuron indices\n",
    "    # Use English labels for the y-axis, preserve original demographic order\n",
    "    \n",
    "    # Create ordered list of English labels matching DEMOGRAPHICS order\n",
    "    demo_en_ordered = [DEMOGRAPHIC_EN[d] for d in DEMOGRAPHICS]\n",
    "    \n",
    "    # Pivot and reindex to maintain original order\n",
    "    pivot_ig2 = df_ig2.pivot(index='Demographic_EN', columns='Layer_Quantile', values='Max_Score')\n",
    "    pivot_ig2 = pivot_ig2.reindex(demo_en_ordered)  # Reorder rows to match DEMOGRAPHICS order\n",
    "    pivot_ig2 = pivot_ig2[['q1', 'q2', 'q3']]\n",
    "    pivot_ig2.columns = ['Layer 8', 'Layer 16', 'Layer 24']\n",
    "    \n",
    "    # Also get neuron indices for annotations\n",
    "    pivot_neuron = df_ig2.pivot(index='Demographic_EN', columns='Layer_Quantile', values='Max_Neuron_Idx')\n",
    "    pivot_neuron = pivot_neuron.reindex(demo_en_ordered)  # Same reordering\n",
    "    pivot_neuron = pivot_neuron[['q1', 'q2', 'q3']]\n",
    "    pivot_neuron.columns = ['Layer 8', 'Layer 16', 'Layer 24']\n",
    "    \n",
    "    # Create custom annotations with score and neuron index\n",
    "    annot_labels = []\n",
    "    for idx in pivot_ig2.index:\n",
    "        row_labels = []\n",
    "        for col in pivot_ig2.columns:\n",
    "            score = pivot_ig2.loc[idx, col]\n",
    "            neuron_idx = int(pivot_neuron.loc[idx, col])\n",
    "            row_labels.append(f'{score:.4f}\\n(#{neuron_idx})')\n",
    "        annot_labels.append(row_labels)\n",
    "    annot_array = np.array(annot_labels)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "    \n",
    "    sns.heatmap(\n",
    "        pivot_ig2,\n",
    "        annot=annot_array,\n",
    "        fmt='',\n",
    "        cmap='YlOrRd',\n",
    "        ax=ax,\n",
    "        cbar_kws={'label': 'Max IG² Score'},\n",
    "        linewidths=0.5,\n",
    "        annot_kws={'fontsize': 10}\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Figure 1: Max IG² Score with Neuron Index (SAE Neuron Importance)\\nby Layer and Demographic', \n",
    "                 fontsize=14, pad=15)\n",
    "    ax.set_xlabel('EXAONE Layer', fontsize=12)\n",
    "    ax.set_ylabel('Demographic Dimension', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"fig1_ig2_max_scores_heatmap_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top neuron indices per demographic (in same order as heatmap)\n",
    "    print(\"\\nStatistics Table: Top Neuron Indices (Max IG² Score) per Demographic:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Demographic':<25} {'Layer 8':>20} {'Layer 16':>20} {'Layer 24':>20}\")\n",
    "    print(\"-\" * 80)\n",
    "    for demo_en in demo_en_ordered:\n",
    "        demo_data = df_ig2[df_ig2['Demographic_EN'] == demo_en]\n",
    "        row = f\"{demo_en:<25}\"\n",
    "        for lq in ['q1', 'q2', 'q3']:\n",
    "            lq_data = demo_data[demo_data['Layer_Quantile'] == lq]\n",
    "            if len(lq_data) > 0:\n",
    "                neuron_idx = lq_data['Max_Neuron_Idx'].values[0]\n",
    "                score = lq_data['Max_Score'].values[0]\n",
    "                row += f\" #{neuron_idx:5d} ({score:.3f})\"\n",
    "            else:\n",
    "                row += f\" {'--':>18}\"\n",
    "        print(row)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "# Figure 2: Distribution of IG² Scores by Layer\n",
    "\n",
    "## How It's Computed:\n",
    "This histogram shows the distribution of all non-zero IG² scores across demographics for each layer. Scores are aggregated from all 9 demographic dimensions to show the overall distribution pattern.\n",
    "\n",
    "## Analysis:\n",
    "A long-tailed distribution with few high-scoring features indicates concentrated bias encoding (good for targeted intervention). More uniform distributions suggest diffuse bias encoding across many features. The log-scale y-axis helps visualize the full range of feature frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_ig2) > 0:\n",
    "    # Distribution of IG² scores for each layer (aggregated across demographics)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    for idx, lq in enumerate(LAYER_QUANTILES):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        lq_data = df_ig2[df_ig2['Layer_Quantile'] == lq]\n",
    "        \n",
    "        if len(lq_data) > 0:\n",
    "            # Concatenate all scores for this layer\n",
    "            all_scores = np.concatenate([row['Scores'] for _, row in lq_data.iterrows()])\n",
    "            \n",
    "            # Plot histogram (only positive scores)\n",
    "            positive_scores = all_scores[all_scores > 0]\n",
    "            ax.hist(positive_scores, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "            ax.set_xlabel('IG² Score', fontsize=11)\n",
    "            ax.set_ylabel('Frequency', fontsize=11)\n",
    "            ax.set_title(f'{LAYER_LABELS[lq]}\\n({len(positive_scores):,} non-zero features)', fontsize=12)\n",
    "            ax.set_yscale('log')\n",
    "            ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Figure 2: IG² Score Distribution by Layer (Aggregated Across All Demographics)', fontsize=14, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"fig2_ig2_distribution_by_layer_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "# Figure 3: Verification Heatmaps (Suppression, Amplification, Z-Score)\n",
    "\n",
    "## How It's Computed:\n",
    "\n",
    "### (1) Suppression Effect:\n",
    "Suppression sets identified bias features to zero and measures the change in logit gap (difference between correct and incorrect demographic predictions). The change ratio = (gap_after - gap_before) / gap_before. Negative values indicate bias reduction - the model becomes less confident in distinguishing demographics.\n",
    "\n",
    "### (2) Amplification Effect:\n",
    "Amplification multiplies identified bias features by 2 (doubling their activation magnitude) and measures the change in logit gap. Positive values indicate bias amplification - the model becomes more confident in distinguishing demographics.\n",
    "\n",
    "### (3) Z-Score (Statistical Significance):\n",
    "Z-score compares the suppression effect to random control: Z = (suppress_change - random_mean) / random_std. It measures how many standard deviations the bias feature suppression differs from suppressing random features. |Z| > 2 indicates statistical significance (p < 0.05).\n",
    "\n",
    "## Statistical Background:\n",
    "- **Null Hypothesis (H₀)**: \"Suppressing bias features has the same effect as suppressing random features.\"\n",
    "- **Alternative Hypothesis (H₁)**: \"Suppressing bias features has a significantly different effect than random features.\"\n",
    "- The threshold |Z| > 1.96 ≈ 2 corresponds to p < 0.05 (95% confidence).\n",
    "\n",
    "## Analysis:\n",
    "- Green cells in suppression (negative values) = successful bias reduction\n",
    "- Red cells in amplification (positive values) = successful bias increase  \n",
    "- True in Z-score panel = statistically significant effect (|Z| > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive verification dataframe\n",
    "verif_summary_data = []\n",
    "\n",
    "for demo in DEMOGRAPHICS:\n",
    "    for lq in LAYER_QUANTILES:\n",
    "        if demo not in verification_data or lq not in verification_data[demo]:\n",
    "            continue\n",
    "        \n",
    "        data = verification_data[demo][lq]\n",
    "        \n",
    "        row = {\n",
    "            'Demographic': demo,\n",
    "            'Demographic_EN': DEMOGRAPHIC_EN[demo],\n",
    "            'Layer': LAYER_LABELS[lq],\n",
    "            'Layer_Quantile': lq,\n",
    "        }\n",
    "        \n",
    "        # Suppression data\n",
    "        if 'suppression' in data:\n",
    "            supp = data['suppression']\n",
    "            row['Suppress_Gap_Before'] = supp.get('gap_before', 0)\n",
    "            row['Suppress_Gap_After'] = supp.get('gap_after', 0)\n",
    "            row['Suppress_Change_Ratio'] = supp.get('gap_change_ratio', 0)\n",
    "            row['Suppress_Num_Features'] = supp.get('metadata', {}).get('num_features_manipulated', 0)\n",
    "        \n",
    "        # Amplification data\n",
    "        if 'amplification' in data:\n",
    "            amp = data['amplification']\n",
    "            row['Amplify_Gap_Before'] = amp.get('gap_before', 0)\n",
    "            row['Amplify_Gap_After'] = amp.get('gap_after', 0)\n",
    "            row['Amplify_Change_Ratio'] = amp.get('gap_change_ratio', 0)\n",
    "        \n",
    "        # Random control data and Z-score\n",
    "        if 'random' in data:\n",
    "            rand = data['random']\n",
    "            row['Random_Mean_Change'] = rand.get('mean_gap_change', 0)\n",
    "            row['Random_Std_Change'] = rand.get('std_gap_change', 0)\n",
    "            \n",
    "            # Calculate Z-score for suppression effect\n",
    "            if row.get('Suppress_Change_Ratio') is not None and rand.get('std_gap_change', 0) > 0:\n",
    "                z_score = (row['Suppress_Change_Ratio'] - rand['mean_gap_change']) / rand['std_gap_change']\n",
    "                row['Z_Score'] = z_score\n",
    "            else:\n",
    "                row['Z_Score'] = 0\n",
    "        \n",
    "        verif_summary_data.append(row)\n",
    "\n",
    "df_verif = pd.DataFrame(verif_summary_data)\n",
    "\n",
    "if len(df_verif) > 0:\n",
    "    print(f\"\\nCollected verification data for {len(df_verif)} experiments\")\n",
    "else:\n",
    "    print(\"No verification data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_verif) > 0:\n",
    "    # Create ordered list of English labels matching DEMOGRAPHICS order\n",
    "    demo_en_ordered = [DEMOGRAPHIC_EN[d] for d in DEMOGRAPHICS]\n",
    "    \n",
    "    # ============================================\n",
    "    # COMBINED HEATMAP: Suppression, Amplification, Statistical Significance\n",
    "    # ============================================\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 8))\n",
    "    \n",
    "    # --- (1) Suppression Effect ---\n",
    "    ax1 = axes[0]\n",
    "    pivot_suppress = df_verif.pivot(index='Demographic_EN', columns='Layer_Quantile', values='Suppress_Change_Ratio')\n",
    "    pivot_suppress = pivot_suppress.reindex(demo_en_ordered)\n",
    "    pivot_suppress = pivot_suppress[['q1', 'q2', 'q3']] * 100  # Convert to percentage\n",
    "    pivot_suppress.columns = ['Layer 8', 'Layer 16', 'Layer 24']\n",
    "    \n",
    "    sns.heatmap(\n",
    "        pivot_suppress,\n",
    "        annot=True,\n",
    "        fmt='.1f',\n",
    "        cmap='RdYlGn_r',\n",
    "        center=0,\n",
    "        ax=ax1,\n",
    "        cbar_kws={'label': 'Gap Change (%)'},\n",
    "        linewidths=0.5,\n",
    "        annot_kws={'fontsize': 10}\n",
    "    )\n",
    "    ax1.set_title('(1) Suppression Effect\\n(Green/Negative = Bias Reduced)', fontsize=12, pad=10)\n",
    "    ax1.set_xlabel('EXAONE Layer', fontsize=11)\n",
    "    ax1.set_ylabel('Demographic Dimension', fontsize=11)\n",
    "    \n",
    "    # --- (2) Amplification Effect (no y-axis) ---\n",
    "    ax2 = axes[1]\n",
    "    pivot_amplify = df_verif.pivot(index='Demographic_EN', columns='Layer_Quantile', values='Amplify_Change_Ratio')\n",
    "    pivot_amplify = pivot_amplify.reindex(demo_en_ordered)\n",
    "    pivot_amplify = pivot_amplify[['q1', 'q2', 'q3']] * 100\n",
    "    pivot_amplify.columns = ['Layer 8', 'Layer 16', 'Layer 24']\n",
    "    \n",
    "    sns.heatmap(\n",
    "        pivot_amplify,\n",
    "        annot=True,\n",
    "        fmt='.1f',\n",
    "        cmap='RdBu_r',\n",
    "        center=0,\n",
    "        ax=ax2,\n",
    "        cbar_kws={'label': 'Gap Change (%)'},\n",
    "        linewidths=0.5,\n",
    "        annot_kws={'fontsize': 10}\n",
    "    )\n",
    "    ax2.set_title('(2) Amplification Effect\\n(Red/Positive = Bias Increased)', fontsize=12, pad=10)\n",
    "    ax2.set_xlabel('EXAONE Layer', fontsize=11)\n",
    "    ax2.set_ylabel('')  # Remove y-axis label\n",
    "    ax2.set_yticklabels([])  # Remove y-axis tick labels\n",
    "    \n",
    "    # --- (3) Statistical Significance (True/False, blue colormap, no y-axis) ---\n",
    "    ax3 = axes[2]\n",
    "    pivot_sig = df_verif.pivot(index='Demographic_EN', columns='Layer_Quantile', values='Z_Score')\n",
    "    pivot_sig = pivot_sig.reindex(demo_en_ordered)\n",
    "    pivot_sig = pivot_sig[['q1', 'q2', 'q3']]\n",
    "    # Convert to True/False based on |Z| > 2\n",
    "    pivot_sig_bool = (abs(pivot_sig) > 2).astype(int)\n",
    "    pivot_sig_bool.columns = ['Layer 8', 'Layer 16', 'Layer 24']\n",
    "    \n",
    "    # Create annotation labels as \"True\" or \"False\"\n",
    "    annot_labels = pivot_sig_bool.applymap(lambda x: 'True' if x == 1 else 'False')\n",
    "    \n",
    "    sns.heatmap(\n",
    "        pivot_sig_bool,\n",
    "        annot=annot_labels,\n",
    "        fmt='',\n",
    "        cmap='Blues',  # Blue colormap for significance\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        ax=ax3,\n",
    "        cbar_kws={'label': 'Significant (|Z|>2)'},\n",
    "        linewidths=0.5,\n",
    "        annot_kws={'fontsize': 10}\n",
    "    )\n",
    "    ax3.set_title('(3) Statistical Significance\\n(|Z-score| > 2)', fontsize=12, pad=10)\n",
    "    ax3.set_xlabel('EXAONE Layer', fontsize=11)\n",
    "    ax3.set_ylabel('')  # Remove y-axis label\n",
    "    ax3.set_yticklabels([])  # Remove y-axis tick labels\n",
    "    \n",
    "    plt.suptitle('Figure 3: Bias Feature Verification - Combined Results by Layer and Demographic', \n",
    "                 fontsize=14, y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ASSETS_DIR / f\"fig3_verification_combined_heatmap_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nSuppression Effect Statistics:\")\n",
    "    print(\"=\" * 60)\n",
    "    for lq in ['q1', 'q2', 'q3']:\n",
    "        lq_data = df_verif[df_verif['Layer_Quantile'] == lq]\n",
    "        if len(lq_data) > 0:\n",
    "            print(f\"\\n{LAYER_LABELS[lq]}:\")\n",
    "            print(f\"  Mean Change:  {lq_data['Suppress_Change_Ratio'].mean()*100:.2f}%\")\n",
    "            print(f\"  Std Change:   {lq_data['Suppress_Change_Ratio'].std()*100:.2f}%\")\n",
    "else:\n",
    "    print(\"No verification data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "# Figure 4: Feature Overlap Between Demographics (Jaccard Similarity)\n",
    "\n",
    "## How It's Computed:\n",
    "For each layer, we compute Jaccard similarity between all pairs of demographics: J(A,B) = |A∩B| / |A∪B|, where A and B are sets of important feature indices (99th percentile of IG² scores). Higher similarity means demographics share more bias-encoding features.\n",
    "\n",
    "## Analysis:\n",
    "- High similarity across demographics within a layer suggests common bias-encoding mechanisms (features that encode \"group identity\" rather than specific biases)\n",
    "- Low similarity means demographic-specific encoding\n",
    "- Comparing across layers reveals where bias is most/least generalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_features_by_percentile(scores, percentile):\n",
    "    \"\"\"\n",
    "    Filter features by percentile threshold on non-zero scores.\n",
    "    \n",
    "    Args:\n",
    "        scores: numpy array of IG² scores\n",
    "        percentile: percentile threshold (e.g., 95, 99)\n",
    "    \n",
    "    Returns:\n",
    "        important_indices: indices of features above threshold\n",
    "        threshold: computed threshold value\n",
    "    \"\"\"\n",
    "    nonzero_scores = scores[scores > 0]\n",
    "    if len(nonzero_scores) == 0:\n",
    "        return np.array([]), 0.0\n",
    "    \n",
    "    threshold = np.percentile(nonzero_scores, percentile)\n",
    "    important_indices = np.where(scores >= threshold)[0]\n",
    "    return important_indices, threshold\n",
    "\n",
    "\n",
    "def compute_jaccard_similarity(set_a, set_b):\n",
    "    \"\"\"Compute Jaccard similarity between two sets.\"\"\"\n",
    "    set_a = set(set_a)\n",
    "    set_b = set(set_b)\n",
    "    \n",
    "    intersection = len(set_a & set_b)\n",
    "    union = len(set_a | set_b)\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute important feature indices for each demographic-layer\n",
    "important_features = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for demo in DEMOGRAPHICS:\n",
    "    for lq in LAYER_QUANTILES:\n",
    "        if lq in ig2_data[demo]:\n",
    "            data = ig2_data[demo][lq]\n",
    "            \n",
    "            # Get feature scores\n",
    "            if isinstance(data, dict):\n",
    "                scores = data.get('feature_scores', data.get('ig2_scores', None))\n",
    "            else:\n",
    "                scores = data\n",
    "            \n",
    "            if scores is not None:\n",
    "                if isinstance(scores, torch.Tensor):\n",
    "                    scores_np = scores.cpu().numpy()\n",
    "                else:\n",
    "                    scores_np = scores\n",
    "                \n",
    "                # Get 99th percentile features\n",
    "                indices, threshold = filter_features_by_percentile(scores_np, 99)\n",
    "                important_features[demo][lq] = {\n",
    "                    'indices': indices,\n",
    "                    'threshold': threshold\n",
    "                }\n",
    "\n",
    "print(\"Computed important feature indices (99th percentile).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Jaccard similarity matrices for each layer\n",
    "jaccard_matrices = {}\n",
    "\n",
    "for lq in LAYER_QUANTILES:\n",
    "    n_demo = len(DEMOGRAPHICS)\n",
    "    matrix = np.zeros((n_demo, n_demo))\n",
    "    \n",
    "    for i, demo_i in enumerate(DEMOGRAPHICS):\n",
    "        for j, demo_j in enumerate(DEMOGRAPHICS):\n",
    "            if i == j:\n",
    "                matrix[i, j] = 1.0\n",
    "            else:\n",
    "                # Get important features for both demographics\n",
    "                if lq in important_features[demo_i] and lq in important_features[demo_j]:\n",
    "                    indices_i = important_features[demo_i][lq]['indices']\n",
    "                    indices_j = important_features[demo_j][lq]['indices']\n",
    "                    matrix[i, j] = compute_jaccard_similarity(indices_i, indices_j)\n",
    "    \n",
    "    jaccard_matrices[lq] = matrix\n",
    "\n",
    "print(\"Jaccard similarity matrices computed for each layer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Jaccard similarity heatmaps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 8))\n",
    "\n",
    "demo_en_labels = [DEMOGRAPHIC_EN[d] for d in DEMOGRAPHICS]\n",
    "\n",
    "for idx, lq in enumerate(LAYER_QUANTILES):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    matrix = jaccard_matrices[lq]\n",
    "    \n",
    "    # Create DataFrame for better labeling\n",
    "    df_matrix = pd.DataFrame(matrix, index=demo_en_labels, columns=demo_en_labels)\n",
    "    \n",
    "    # Mask diagonal for cleaner visualization\n",
    "    mask = np.eye(len(DEMOGRAPHICS), dtype=bool)\n",
    "    \n",
    "    sns.heatmap(\n",
    "        df_matrix,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='YlGnBu',\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        ax=ax,\n",
    "        mask=mask,\n",
    "        cbar=True if idx == 2 else False,\n",
    "        cbar_kws={'label': 'Jaccard Similarity'} if idx == 2 else None,\n",
    "        linewidths=0.5,\n",
    "        annot_kws={'fontsize': 8}\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f'{LAYER_LABELS[lq]}', fontsize=12, pad=10)\n",
    "    ax.tick_params(axis='x', rotation=75)  # Set x-axis rotation to 75 degrees\n",
    "    ax.tick_params(axis='y', rotation=0)\n",
    "    \n",
    "    # Remove y-axis for Layer 16 and Layer 24 (idx > 0)\n",
    "    if idx > 0:\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "plt.suptitle('Figure 4: Feature Overlap Between Demographics (99th Percentile with Jaccard Similarity)', \n",
    "             fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ASSETS_DIR / f\"fig4_jaccard_similarity_{STAGE}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print average similarity per layer\n",
    "print(\"\\nAverage Jaccard Similarity (excluding diagonal):\")\n",
    "print(\"=\" * 60)\n",
    "for lq in LAYER_QUANTILES:\n",
    "    matrix = jaccard_matrices[lq]\n",
    "    # Get off-diagonal elements\n",
    "    off_diag = matrix[~np.eye(matrix.shape[0], dtype=bool)]\n",
    "    print(f\"  {LAYER_LABELS[lq]}: {off_diag.mean():.3f} (std={off_diag.std():.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jn1l3q6xiti",
   "source": "---\n# Figure 5: Feature Sharing Distribution\n\n## How It's Computed:\nFor each layer, we collect all important features (99th percentile) across all 9 demographics and count how many demographics share each feature. Features are then grouped by their sharing count: unique (1 demographic), partially shared (2-4 demographics), or universal (5+ demographics).\n\n## Why This Matters:\nThis analysis reveals the nature of bias encoding in the model:\n- **Many unique features** → Bias encoding is demographic-specific (each demographic has its own distinct features)\n- **Many shared features** → Bias encoding uses common mechanisms (a smaller set of \"group identity\" features)\n\n## Analysis:\nA distribution skewed toward unique features suggests targeted, demographic-specific interventions are needed. A distribution with many shared features suggests that intervening on a small set of universal features could reduce bias across multiple demographics simultaneously.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "87jf9lfp99s",
   "source": "# Compute feature sharing distribution for each layer\nsharing_data = []\n\nfor lq in LAYER_QUANTILES:\n    # Collect all important features for this layer\n    all_features = {}\n    for demo in DEMOGRAPHICS:\n        if lq in important_features[demo]:\n            all_features[demo] = set(important_features[demo][lq]['indices'])\n    \n    # Count how many demographics each feature appears in\n    feature_counts = defaultdict(int)\n    for demo, features in all_features.items():\n        for f in features:\n            feature_counts[f] += 1\n    \n    # Group by sharing count\n    for feature_idx, count in feature_counts.items():\n        sharing_data.append({\n            'Layer': lq,\n            'Layer_Label': LAYER_LABELS[lq],\n            'Feature_Index': feature_idx,\n            'Shared_By_N_Demographics': count\n        })\n\ndf_sharing = pd.DataFrame(sharing_data)\n\n# Create distribution summary\ndistribution_summary = []\nfor lq in LAYER_QUANTILES:\n    lq_data = df_sharing[df_sharing['Layer'] == lq]\n    total = len(lq_data)\n    \n    for n in range(1, 10):  # 1 to 9 demographics\n        count = len(lq_data[lq_data['Shared_By_N_Demographics'] == n])\n        if count > 0:\n            distribution_summary.append({\n                'Layer': LAYER_LABELS[lq],\n                'Shared_By': n,\n                'Feature_Count': count,\n                'Percentage': count / total * 100 if total > 0 else 0\n            })\n\ndf_distribution = pd.DataFrame(distribution_summary)\nprint(\"Feature sharing distribution computed.\")\nprint(df_distribution)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "zyynzbyv5o",
   "source": "# Visualize feature sharing distribution\nfig, ax = plt.subplots(figsize=(12, 6))\n\n# Pivot for grouped bar chart\npivot = df_distribution.pivot(index='Shared_By', columns='Layer', values='Feature_Count')\npivot = pivot.fillna(0).astype(int)\npivot = pivot[['Layer 8', 'Layer 16', 'Layer 24']]  # Reorder columns\n\n# Create grouped bar chart\nx = np.arange(len(pivot.index))\nwidth = 0.25\ncolors = ['#3498db', '#2ecc71', '#e74c3c']  # Blue, Green, Red\n\nfor i, (col, color) in enumerate(zip(pivot.columns, colors)):\n    ax.bar(x + i * width, pivot[col], width, label=col, color=color, alpha=0.8)\n\nax.set_xlabel('Number of Demographics Sharing the Feature', fontsize=12)\nax.set_ylabel('Number of Features', fontsize=12)\nax.set_title('Figure 5: Feature Sharing Distribution (99th Percentile)\\nHow Many Demographics Share Each Important Feature?', \n             fontsize=14, pad=15)\nax.set_xticks(x + width)\nax.set_xticklabels(pivot.index)\nax.legend(title='Layer', loc='upper right')\nax.grid(axis='y', alpha=0.3)\n\n# Add category labels\nax.axvline(x=0.5, color='gray', linestyle='--', alpha=0.3)\nax.axvline(x=4.5, color='gray', linestyle='--', alpha=0.3)\nax.text(0.0, ax.get_ylim()[1] * 0.95, 'Unique', fontsize=10, ha='center', style='italic', color='gray')\nax.text(2.5, ax.get_ylim()[1] * 0.95, 'Partially Shared', fontsize=10, ha='center', style='italic', color='gray')\nax.text(6.5, ax.get_ylim()[1] * 0.95, 'Universal', fontsize=10, ha='center', style='italic', color='gray')\n\nplt.tight_layout()\nplt.savefig(ASSETS_DIR / f\"fig5_feature_sharing_distribution_{STAGE}.png\", dpi=300, bbox_inches='tight')\nplt.show()\n\n# Print summary statistics\nprint(\"\\nFeature Sharing Summary:\")\nprint(\"=\" * 70)\nfor lq in LAYER_QUANTILES:\n    lq_data = df_sharing[df_sharing['Layer'] == lq]\n    total = len(lq_data)\n    unique = len(lq_data[lq_data['Shared_By_N_Demographics'] == 1])\n    partial = len(lq_data[(lq_data['Shared_By_N_Demographics'] >= 2) & (lq_data['Shared_By_N_Demographics'] <= 4)])\n    universal = len(lq_data[lq_data['Shared_By_N_Demographics'] >= 5])\n    \n    print(f\"\\n{LAYER_LABELS[lq]} ({total} total features):\")\n    print(f\"  Unique (1 demo):           {unique:3d} ({unique/total*100:.1f}%)\")\n    print(f\"  Partially shared (2-4):    {partial:3d} ({partial/total*100:.1f}%)\")\n    print(f\"  Universal (5+ demos):      {universal:3d} ({universal/total*100:.1f}%)\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"INSIGHT: Features shared by 5+ demographics are 'universal bias features'\")\nprint(\"that may encode general group identity rather than specific demographic bias.\")\nprint(\"=\" * 70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": "---\n# Summary\n\nThis notebook extracted the 6 key figures from the Korean Bias SAE analysis:\n\n0. **Figure 0**: Probe Accuracy - **Justifies the probing approach** by showing high classification accuracy across all demographics and layers\n1. **Figure 1**: IG² Score Comparison - Shows max importance scores and neuron indices for each demographic-layer combination\n2. **Figure 2**: IG² Distribution - Histograms showing the spread of importance scores across layers\n3. **Figure 3**: Verification Heatmaps - Confirms causal relationship between identified features and bias through suppression/amplification tests\n4. **Figure 4**: Feature Overlap - Jaccard similarity showing how much demographics share bias-encoding features\n5. **Figure 5**: Feature Sharing Distribution - Shows whether bias encoding is demographic-specific (unique features) or uses common mechanisms (shared features)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary Key Figures Notebook Complete!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nAssets saved to: {ASSETS_DIR}\")\n",
    "print(\"\\nGenerated figures:\")\n",
    "for f in sorted(ASSETS_DIR.glob(f\"fig*_{STAGE}*\")):\n",
    "    print(f\"  - {f.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}