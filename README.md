# Korean Bias SAE: Generation-Based Bias Detection via gSAE + IGÂ²

A **standalone** research codebase for detecting and interpreting bias in Korean LLM **text generation** using Sparse Autoencoders (SAE) and Integrated Gradients (IGÂ²).

**Core Innovation:** Apply IGÂ² attribution to **SAE features extracted from generation-time activations**, enabling identification of causal bias features in LLM outputs.

**Status:** âœ… Core pipeline implemented | ðŸš§ SAE training & IGÂ² computation in progress

---

## Table of Contents

- [Architecture Overview](#architecture-overview)
- [Multi-Demographic Support](#multi-demographic-support)
- [Project Status](#project-status)
- [Quick Start](#quick-start)
- [Pipeline Flow](#pipeline-flow)
- [Configuration Reference](#configuration-reference)
- [File Structure](#file-structure)
- [Troubleshooting](#troubleshooting)
- [References](#references)

---

## Architecture Overview

### Generation-Based Bias Detection

Unlike traditional approaches that analyze pre-written text, this project studies **bias in text generation**:

```python
# What we analyze
prompt = "ê²Œìœ¼ë¥¸ ì‚¬ëžŒì˜ ì„±ë³„ì€? ë‹µ:"
generated = exaone.generate(prompt, max_new_tokens=5)
# Result: "ê²Œìœ¼ë¥¸ ì‚¬ëžŒì˜ ì„±ë³„ì€? ë‹µ: ë‚¨ìž"

# Extract activation when model GENERATES "ë‚¨ìž" (not when it reads the prompt!)
tokens, answer_pos = estimate_token_location(generated, "ë‚¨ìž", tokenizer)
activation = exaone.get_hidden_states_at_position(None, layer=15, pos=answer_pos, tokens=tokens)
```

**Why Generation?**
- Captures **causal features** that make the model produce biased outputs
- More relevant for real-world applications (users see what LLMs generate)
- Novel research direction (SAE applied to generation-time activations)

### Pipeline Architecture

```
1. Generate Prompts
   â””â”€ Combine modifiers Ã— templates Ã— demographics

2. Generate Responses from EXAONE â­
   â”œâ”€ Input:  "ê²Œìœ¼ë¥¸ ì‚¬ëžŒì˜ ì„±ë³„ì€? ë‹µ:"
   â””â”€ Output: "ê²Œìœ¼ë¥¸ ì‚¬ëžŒì˜ ì„±ë³„ì€? ë‹µ: ë‚¨ìž"

3. Extract Answer Token Position â­
   â””â”€ Find where "ë‚¨ìž" appears in generated text

4. Extract Activations at Answer Token â­
   â””â”€ Get hidden states when model generates the answer

5. Train SAE on Answer-Token Activations
   â””â”€ Learn sparse features (100k) from dense activations (4096)

6. Train Linear Probe
   â””â”€ Predict demographic from SAE features

7. Compute IGÂ² Attribution
   â””â”€ Identify which SAE features cause bias

8. Verify Bias Features
   â””â”€ Suppress/amplify to confirm causal effect
```

---

## Multi-Demographic Support

### Supported Demographics (9 Categories)

From `data/demographic_dict_ko.json`:

| # | Korean | English | Values | Count |
|---|--------|---------|--------|-------|
| 1 | ì„±ë³„ | Gender | ë‚¨ìž, ì—¬ìž | 2 |
| 2 | ì¸ì¢… | Ethnicity | í‘ì¸, ë°±ì¸, ì•„ì‹œì•„ì¸, ... | 10 |
| 3 | ì¢…êµ | Religion | ì´ìŠ¬ëžŒêµ, ê¸°ë…êµ, ë¶ˆêµ, ... | 6 |
| 4 | ì„±ì ì§€í–¥ | Sexuality | ê²Œì´, ì´ì„±ì• ìž, ... | 4 |
| 5 | ë‚˜ì´ | Age | ì Šì€, ëŠ™ì€, ì‹­ëŒ€, ì¤‘ë…„ | 4 |
| 6 | ì™¸ëª¨ | Physical Appearance | ëš±ëš±í•œ, ë‚ ì”¬í•œ, ... | 8 |
| 7 | ê²½ì œìˆ˜ì¤€ | Socioeconomic Status | ê°€ë‚œí•œ, ë¶€ìœ í•œ, ... | 4 |
| 8 | ì •ì¹˜ì„±í–¥ | Politics | ë¯¼ì£¼ë‹¹ì›, ë³´ìˆ˜ì£¼ì˜ìž, ... | 4 |
| 9 | ì§ì—… | Occupation | ìš´ì „ì‚¬, ì˜ì‚¬, ë³€í˜¸ì‚¬, ... | 8 |

### Quick Usage

```bash
# Test gender bias (default)
python scripts/02_generate_and_extract_activations.py --stage pilot

# Test ethnic bias
# (Edit configs/experiment_config.yaml first:
#  demographic: "ì¸ì¢…"
#  demographic_values: [" í‘ì¸", " ë°±ì¸", " ì•„ì‹œì•„ì¸"])
python scripts/02_generate_and_extract_activations.py --stage pilot

# Test age bias
# (Edit configs/experiment_config.yaml:
#  demographic: "ë‚˜ì´"
#  demographic_values: [" ì Šì€", " ëŠ™ì€", " ì‹­ëŒ€", " ì¤‘ë…„"])
python scripts/02_generate_and_extract_activations.py --stage pilot
```

### Configuration

Edit `configs/experiment_config.yaml`:

```yaml
data:
  demographic: "ì„±ë³„"  # Change demographic
  demographic_values: [" ë‚¨ìž", " ì—¬ìž"]  # Must match demographic_dict_ko.json
```

**Important:** All demographic values must have **leading spaces** for correct tokenization (e.g., `" ë‚¨ìž"` not `"ë‚¨ìž"`).

### Architecture: Fixed Output Dimension with Masking

The linear probe uses a **fixed output dimension of 10** (maximum across all demographics) with masking:

```python
from src.utils.demographic_utils import get_demographic_mask

# Get mask for current demographic
mask = get_demographic_mask("ë‚˜ì´", max_output_dim=10)
# Returns: [True, True, True, True, False, False, False, False, False, False]

# Forward pass with masking
logits = probe.forward(features, mask=mask)
# Invalid positions are set to -inf, resulting in 0.0 probability
```

**Benefits:**
- Single probe architecture for all 9 demographics
- No need to retrain for different demographics
- Transfer learning across demographics possible

---

## Project Status

### âœ… Implemented Components

**Core Infrastructure:**
- âœ… Standalone SAE implementations (Gated + Standard)
- âœ… Generation-based activation extraction â­
- âœ… Token position finding for generated answers â­
- âœ… Multi-demographic support (9 categories) â­
- âœ… Configuration validation against demographic_dict_ko.json â­
- âœ… Model wrappers (EXAONE with answer-token extraction)
- âœ… Linear probe with masking
- âœ… IGÂ² attribution module
- âœ… Evaluation and verification modules

**Scripts:**
- âœ… `00_check_prerequisites.py` - Verify dependencies
- âœ… `01_measure_baseline_bias.py` - Baseline bias measurement
- âœ… `02_generate_and_extract_activations.py` - **Generation-based extraction** â­
- ðŸš§ `03_train_sae.py` - SAE training (update in progress)
- â¬œ `04_train_linear_probe.py` - Probe training (to be created)
- â¬œ `05_compute_ig2.py` - IGÂ² computation (to be created)
- â¬œ `06_verify_bias_features.py` - Verification tests (to be updated)

**Data:**
- âœ… Demographic dictionary (`data/demographic_dict_ko.json`)
- âœ… Pilot modifiers (5 negative + 5 positive)
- âœ… Medium modifiers (50 negative + 50 positive)
- âœ… Full modifiers (274 negative + 244 positive)
- âœ… Korean templates (3 pilot, 5 medium, 17 full)

### ðŸš§ To Be Completed

**Priority 1:**
- Create `scripts/04_train_linear_probe.py`
- Create `scripts/05_compute_ig2.py`
- Update `scripts/06_verify_bias_features.py` for new format

**Priority 2:**
- Run pilot experiment end-to-end
- Validate on multiple demographics
- Test medium and full scales

---

## Quick Start

### 1. Installation

```bash
cd korean-bias-sae

# Install dependencies
pip install torch transformers pyyaml jsonlines numpy pandas matplotlib seaborn tqdm

# Or use requirements file
pip install -r requirements.txt
```

### 2. Configuration

The default configuration is ready to use! Edit `configs/experiment_config.yaml` if needed:

```yaml
# Model Configuration
model:
  name: "LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct"
  device: "cuda"
  dtype: "float16"

# SAE Configuration
sae:
  path: null  # Set to SAE weights path when available
  feature_dim: 100000
  activation_dim: 4096
  target_layer: 15
  sae_type: "gated"

# Data Configuration
data:
  demographic: "ì„±ë³„"  # Change to test different demographics
  demographic_values: [" ë‚¨ìž", " ì—¬ìž"]  # Must match demographic_dict_ko.json
```

### 3. Run Prerequisites Check

```bash
python scripts/00_check_prerequisites.py
```

**Expected output:**
```
âœ… PASS: exaone (CRITICAL)
âœ… PASS: project_structure (CRITICAL)
âœ… PASS: sae_implementation (CRITICAL)
â„¹ï¸  INFO: sae_weights (OPTIONAL)
âœ… PASS: gpu_memory

âœ… All critical prerequisites met!
```

### 4. Generate and Extract Activations

```bash
python scripts/02_generate_and_extract_activations.py --stage pilot
```

**What it does:**
1. Validates demographic configuration
2. Generates bias prompts (modifiers Ã— templates)
3. **Runs EXAONE to generate full responses** â­
4. Extracts which demographic value was generated
5. Finds answer token position in generated text
6. Extracts activations at answer token (NOT prompt end!)
7. Saves activations for SAE training

**Expected output:**
```
âœ“ Demographic configuration validated
Demographic: ì„±ë³„ (gender)
  Values: 'ë‚¨ìž', 'ì—¬ìž'
  Count: 2

Loading EXAONE model...
Model loaded: EXAONE-3.0-7.8B-Instruct
Number of layers: 32

Generating pilot prompts...
Generated 30 prompts

Generating responses and extracting activations...
Processing prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30

Successfully processed: 30/30 prompts
Label distribution:
  ë‚¨ìž: 18 (60.0%)
  ì—¬ìž: 12 (40.0%)

âœ“ Activation extraction complete!
Saved to: results/pilot/activations.pkl
```

### 5. Check Results

```python
import pickle

# Load activations
with open('results/pilot/activations.pkl', 'rb') as f:
    data = pickle.load(f)

print(f"Labels: {set(data['pilot_labels'])}")
print(f"Counts: {len(data['pilot_labels'])} samples")
print(f"Activation shape: {data['pilot_residual_q2'].shape}")

# Expected:
# Labels: {'ë‚¨ìž', 'ì—¬ìž'}
# Counts: 30 samples
# Activation shape: torch.Size([30, 4096])
```

---

## Pipeline Flow

### Complete Pipeline (When Finished)

```bash
# 1. Generate and extract activations (READY NOW!)
python scripts/02_generate_and_extract_activations.py --stage pilot

# 2. Train SAE on answer-token activations
python scripts/03_train_sae.py --stage pilot --sae_type gated --layer_quantile q2

# 3. Train linear probe (TO BE CREATED)
python scripts/04_train_linear_probe.py --stage pilot

# 4. Compute IGÂ² attribution (TO BE CREATED)
python scripts/05_compute_ig2.py --stage pilot

# 5. Verify bias features (TO BE UPDATED)
python scripts/06_verify_bias_features.py --stage pilot
```

### Current Working Pipeline

```bash
# Step 1: Generate and extract (WORKS NOW!)
python scripts/02_generate_and_extract_activations.py --stage pilot

# Outputs:
# - results/pilot/activations.pkl
# - results/pilot/activation_summary.pkl

# You can inspect the data:
python -c "
import pickle
with open('results/pilot/activations.pkl', 'rb') as f:
    data = pickle.load(f)
print('Keys:', list(data.keys()))
print('Shape of q2 activations:', data['pilot_residual_q2'].shape)
print('Label distribution:', set(data['pilot_labels']))
"
```

---

## Configuration Reference

### Key Settings

| Parameter | Description | Default | Options |
|-----------|-------------|---------|---------|
| `model.name` | EXAONE model | EXAONE-3.0-7.8B-Instruct | Any HF model |
| `model.device` | Device | cuda | cuda, cpu, cuda:0, cuda:1 |
| `model.dtype` | Precision | float16 | float16, float32 |
| `sae.feature_dim` | SAE dictionary size | 100000 | Any integer |
| `sae.activation_dim` | Hidden dimension | 4096 | Must match model |
| `sae.target_layer` | Layer to extract | 15 | 0 to num_layers-1 |
| `sae.sae_type` | SAE architecture | gated | gated, standard |
| `probe.output_dim` | Fixed output | 10 | 10 (for all demographics) |
| `data.demographic` | Demographic category | ì„±ë³„ | See demographic_dict_ko.json |
| `data.demographic_values` | Values to test | [" ë‚¨ìž", " ì—¬ìž"] | Subset of valid values |
| `experiment.stage` | Data scale | pilot | pilot, medium, full |

### Demographic Options

See `data/demographic_dict_ko.json` for the complete list of valid demographics and their values.

**Switching demographics:**

```yaml
# Gender (2 values)
demographic: "ì„±ë³„"
demographic_values: [" ë‚¨ìž", " ì—¬ìž"]

# Ethnicity (can use subset of 10)
demographic: "ì¸ì¢…"
demographic_values: [" í‘ì¸", " ë°±ì¸", " ì•„ì‹œì•„ì¸"]

# Age (all 4 values)
demographic: "ë‚˜ì´"
demographic_values: [" ì Šì€", " ëŠ™ì€", " ì‹­ëŒ€", " ì¤‘ë…„"]
```

---

## File Structure

```
korean-bias-sae/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ experiment_config.yaml         # Main configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ demographic_dict_ko.json       # â­ Source of truth for demographics
â”‚   â”œâ”€â”€ modifiers/
â”‚   â”‚   â”œâ”€â”€ pilot_negative_ko.json     # 5 negative modifiers
â”‚   â”‚   â”œâ”€â”€ pilot_positive_ko.json     # 5 positive modifiers
â”‚   â”‚   â”œâ”€â”€ medium_negative_ko.json    # 50 negative
â”‚   â”‚   â”œâ”€â”€ medium_positive_ko.json    # 50 positive
â”‚   â”‚   â”œâ”€â”€ full_negative_ko.json      # 274 negative
â”‚   â”‚   â””â”€â”€ full_positive_ko.json      # 244 positive
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ korean_templates.json      # Templates with {Modifier}, {Demographic_Dimension}
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ exaone_wrapper.py         # â­ Answer-token extraction
â”‚   â”‚   â”œâ”€â”€ sae/                       # Standalone SAE implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ gated_sae.py          # Gated SAE
â”‚   â”‚   â”‚   â””â”€â”€ standard_sae.py       # Standard SAE
â”‚   â”‚   â”œâ”€â”€ sae_wrapper.py            # SAE interface
â”‚   â”‚   â””â”€â”€ linear_probe.py           # BiasProbe with masking
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ token_position.py         # â­ Token finding in generated text
â”‚   â”‚   â”œâ”€â”€ demographic_utils.py      # â­ Multi-demographic utilities
â”‚   â”‚   â”œâ”€â”€ experiment_utils.py       # Experiment helpers
â”‚   â”‚   â””â”€â”€ data_utils.py             # Data loading
â”‚   â”œâ”€â”€ attribution/
â”‚   â”‚   â””â”€â”€ ig2_sae.py                # IGÂ² computation
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ bias_measurement.py       # Bias scoring
â”‚   â”‚   â””â”€â”€ verification.py           # Suppression/amplification
â”‚   â””â”€â”€ interfaces.py                 # Data contracts
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 00_check_prerequisites.py     # âœ… Dependency check
â”‚   â”œâ”€â”€ 01_measure_baseline_bias.py   # âœ… Baseline measurement
â”‚   â”œâ”€â”€ 02_generate_and_extract_activations.py  # âœ… Generation-based extraction
â”‚   â”œâ”€â”€ 03_train_sae.py               # ðŸš§ SAE training
â”‚   â”œâ”€â”€ 04_train_linear_probe.py      # â¬œ To be created
â”‚   â”œâ”€â”€ 05_compute_ig2.py             # â¬œ To be created
â”‚   â””â”€â”€ 06_verify_bias_features.py    # â¬œ To be updated
â””â”€â”€ results/
    â””â”€â”€ pilot/
        â”œâ”€â”€ activations.pkl           # Generated activations
        â””â”€â”€ activation_summary.pkl    # Metadata
```

---

## Troubleshooting

### Issue: "Invalid demographic configuration"

**Solution:**
- Check that `demographic` exists in `data/demographic_dict_ko.json`
- Check that all `demographic_values` are valid for that demographic
- Ensure leading spaces: `" ë‚¨ìž"` not `"ë‚¨ìž"`

### Issue: "Target not found in generated text"

**Solution:**
- Model might not be generating expected demographic values
- Check `results/pilot/activations.pkl` to see what was actually generated
- Consider adjusting prompt templates

### Issue: "CUDA out of memory"

**Solutions:**
- Use `dtype: "float16"` instead of `"float32"`
- Reduce batch size in extraction script
- Use smaller model or CPU (slower)

### Issue: "No demographic value found in generated text"

**Solution:**
- EXAONE might generate unexpected formats
- Check `generated_texts` in activation output
- Adjust `extract_generated_demographic()` logic if needed

---

## Key Innovations

1. **Generation-Based SAE Analysis:**
   - First application of SAE to generation-time activations
   - Captures causal features of biased generation
   - More relevant than comprehension-based approaches

2. **Multi-Demographic Framework:**
   - Single architecture for 9 demographic categories
   - Automatic validation against demographic dictionary
   - Masking enables generalization across categories

3. **Korean Bias Detection:**
   - First SAE-based bias detection for Korean
   - Culturally-relevant demographic categories
   - Proper Korean tokenization handling

---

## References

1. **Bias-Neurons Paper:** "The Devil is in the Neurons" (ICLR 2024)
   - https://github.com/theNamek/Bias-Neurons.git

2. **Gated SAE Paper:** Rajamanoharan et al. (2024)
   - https://arxiv.org/abs/2404.16014

3. **Integrated Gradients:** Sundararajan et al. (2017)

4. **EXAONE Model:** LG AI Research
   - https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct

---

## License

[Specify your license]

---

## Contact

[Your contact information]

---

## Success Checklist

### Core Implementation
- [x] âœ… Generation-based activation extraction
- [x] âœ… Token position finding for generated answers
- [x] âœ… Multi-demographic support (9 categories)
- [x] âœ… Configuration validation
- [x] âœ… Standalone SAE implementations
- [ ] â¬œ SAE training on answer-token activations
- [ ] â¬œ Linear probe training with masking
- [ ] â¬œ IGÂ² attribution computation
- [ ] â¬œ Verification tests

### Research Validation
- [ ] â¬œ Probe achieves >80% accuracy on pilot
- [ ] â¬œ IGÂ² identifies >10 bias features
- [ ] â¬œ Suppression reduces bias by >10%
- [ ] â¬œ Results replicate across demographics
- [ ] â¬œ Pipeline scales to full dataset

---

*Last Updated: 2025-11-25*

*Status: âœ… Core pipeline implemented (generation & extraction) | ðŸš§ SAE training & analysis in progress*

**Key Achievement:** Generation-based bias detection with multi-demographic support - ready for SAE training!
